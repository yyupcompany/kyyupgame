#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®å¤§æ–‡ä»¶æ‰«æå™¨
æ‰«æé¡¹ç›®ä¸­è¶…è¿‡æŒ‡å®šå¤§å°çš„æ–‡ä»¶ï¼Œç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
"""

import os
import sys
from pathlib import Path
from typing import List, Dict, Tuple
from datetime import datetime
import json


class LargeFileScanner:
    """å¤§æ–‡ä»¶æ‰«æå™¨"""

    def __init__(self, scan_path: str = ".", min_size_mb: int = 100):
        """
        åˆå§‹åŒ–æ‰«æå™¨

        Args:
            scan_path: æ‰«æè·¯å¾„ï¼Œé»˜è®¤ä¸ºå½“å‰ç›®å½•
            min_size_mb: æœ€å°æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰ï¼Œé»˜è®¤100MB
        """
        self.scan_path = Path(scan_path).resolve()
        self.min_size_bytes = min_size_mb * 1024 * 1024
        self.large_files = []
        self.scan_stats = {
            'total_files': 0,
            'total_size': 0,
            'large_files_count': 0,
            'large_files_size': 0,
            'scanned_dirs': 0
        }

    def format_size(self, size_bytes: int) -> str:
        """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°æ˜¾ç¤º"""
        for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
            if size_bytes < 1024.0:
                return f"{size_bytes:.1f}{unit}"
            size_bytes /= 1024.0
        return f"{size_bytes:.1f}PB"

    def should_scan_file(self, file_path: Path) -> bool:
        """åˆ¤æ–­æ–‡ä»¶æ˜¯å¦åº”è¯¥è¢«æ‰«æ"""
        # æ’é™¤çš„ç›®å½•
        exclude_dirs = {
            '.git', 'node_modules', '.npm', '.cache', 'dist', 'build',
            '__pycache__', '.pytest_cache', 'coverage', '.nyc_output',
            '.vscode', '.idea', 'vendor', '.venv', 'venv', 'env'
        }

        # æ’é™¤çš„æ–‡ä»¶æ‰©å±•å
        exclude_extensions = {
            '.log', '.tmp', '.temp', '.swp', '.swo', '.lock',
            '.pid', '.DS_Store', 'Thumbs.db'
        }

        # æ£€æŸ¥è·¯å¾„ä¸­æ˜¯å¦åŒ…å«æ’é™¤çš„ç›®å½•
        for exclude_dir in exclude_dirs:
            if exclude_dir in file_path.parts:
                return False

        # æ£€æŸ¥æ–‡ä»¶æ‰©å±•å
        if file_path.suffix.lower() in exclude_extensions:
            return False

        # æ£€æŸ¥æ˜¯å¦ä¸ºç¬¦å·é“¾æ¥
        if file_path.is_symlink():
            return False

        return True

    def scan_directory(self, directory: Path) -> None:
        """é€’å½’æ‰«æç›®å½•"""
        try:
            for item in directory.rglob('*'):
                if item.is_file() and self.should_scan_file(item):
                    self.scan_stats['total_files'] += 1

                    try:
                        file_size = item.stat().st_size
                        self.scan_stats['total_size'] += file_size

                        if file_size >= self.min_size_bytes:
                            file_info = {
                                'path': str(item.relative_to(self.scan_path)),
                                'absolute_path': str(item),
                                'size_bytes': file_size,
                                'size_mb': file_size / (1024 * 1024),
                                'size_formatted': self.format_size(file_size),
                                'modified_time': datetime.fromtimestamp(item.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S'),
                                'file_type': item.suffix.lower() or 'æ— æ‰©å±•å'
                            }
                            self.large_files.append(file_info)
                            self.scan_stats['large_files_count'] += 1
                            self.scan_stats['large_files_size'] += file_size

                    except (OSError, PermissionError) as e:
                        print(f"è­¦å‘Šï¼šæ— æ³•è®¿é—®æ–‡ä»¶ {item}ï¼š{e}")
                        continue

                elif item.is_dir() and not any(exclude in str(item) for exclude in ['.git', 'node_modules']):
                    self.scan_stats['scanned_dirs'] += 1

        except (OSError, PermissionError) as e:
            print(f"è­¦å‘Šï¼šæ— æ³•æ‰«æç›®å½• {directory}ï¼š{e}")

    def generate_report(self, output_format: str = 'text') -> str:
        """ç”Ÿæˆæ‰«ææŠ¥å‘Š"""
        if not self.large_files:
            return f"ğŸ‰ æ­å–œï¼æœªå‘ç°è¶…è¿‡ {self.min_size_bytes / (1024*1024):.0f}MB çš„å¤§æ–‡ä»¶"

        # æŒ‰æ–‡ä»¶å¤§å°æ’åº
        sorted_files = sorted(self.large_files, key=lambda x: x['size_bytes'], reverse=True)

        if output_format == 'json':
            return self._generate_json_report(sorted_files)
        else:
            return self._generate_text_report(sorted_files)

    def _generate_text_report(self, sorted_files: List[Dict]) -> str:
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 80)
        report_lines.append("ğŸ” é¡¹ç›®å¤§æ–‡ä»¶æ‰«ææŠ¥å‘Š")
        report_lines.append("=" * 80)
        report_lines.append(f"ğŸ“ æ‰«æè·¯å¾„: {self.scan_path}")
        report_lines.append(f"ğŸ“ å¤§æ–‡ä»¶é˜ˆå€¼: {self.min_size_bytes / (1024*1024):.0f}MB")
        report_lines.append(f"ğŸ“… æ‰«ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")

        # ç»Ÿè®¡ä¿¡æ¯
        report_lines.append("ğŸ“Š æ‰«æç»Ÿè®¡:")
        report_lines.append(f"  â€¢ æ€»æ–‡ä»¶æ•°: {self.scan_stats['total_files']:,}")
        report_lines.append(f"  â€¢ æ€»å¤§å°: {self.format_size(self.scan_stats['total_size'])}")
        report_lines.append(f"  â€¢ å¤§æ–‡ä»¶æ•°é‡: {self.scan_stats['large_files_count']}")
        report_lines.append(f"  â€¢ å¤§æ–‡ä»¶æ€»å¤§å°: {self.format_size(self.scan_stats['large_files_size'])}")
        report_lines.append(f"  â€¢ å¤§æ–‡ä»¶å æ¯”: {self.scan_stats['large_files_size'] / self.scan_stats['total_size'] * 100:.1f}%")
        report_lines.append("")

        # å¤§æ–‡ä»¶åˆ—è¡¨
        report_lines.append("ğŸš¨ å¤§æ–‡ä»¶è¯¦æƒ…:")
        report_lines.append("-" * 80)
        report_lines.append(f"{'åºå·':<4} {'å¤§å°':<10} {'ä¿®æ”¹æ—¶é—´':<20} {'ç±»å‹':<8} {'è·¯å¾„'}")
        report_lines.append("-" * 80)

        for i, file_info in enumerate(sorted_files, 1):
            report_lines.append(
                f"{i:<4} {file_info['size_formatted']:<10} {file_info['modified_time']:<20} "
                f"{file_info['file_type']:<8} {file_info['path']}"
            )

        report_lines.append("")

        # æ–‡ä»¶ç±»å‹åˆ†æ
        type_stats = {}
        for file_info in sorted_files:
            file_type = file_info['file_type']
            if file_type not in type_stats:
                type_stats[file_type] = {'count': 0, 'size': 0}
            type_stats[file_type]['count'] += 1
            type_stats[file_type]['size'] += file_info['size_bytes']

        if type_stats:
            report_lines.append("ğŸ“ˆ æ–‡ä»¶ç±»å‹åˆ†æ:")
            report_lines.append("-" * 40)
            for file_type, stats in sorted(type_stats.items(),
                                         key=lambda x: x[1]['size'], reverse=True):
                report_lines.append(
                    f"  {file_type or 'æ— æ‰©å±•å'}: {stats['count']}ä¸ª, "
                    f"{self.format_size(stats['size'])}"
                )

        report_lines.append("")
        report_lines.append("ğŸ’¡ å»ºè®®:")
        report_lines.append("  â€¢ æ£€æŸ¥æ˜¯å¦åŒ…å«åœ¨ç‰ˆæœ¬æ§åˆ¶ä¸­çš„å¤§æ–‡ä»¶")
        report_lines.append("  â€¢ è€ƒè™‘ä½¿ç”¨ .gitignore æ’é™¤ä¸å¿…è¦çš„å¤§æ–‡ä»¶")
        report_lines.append("  â€¢ æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤çš„å¤§æ–‡ä»¶")
        report_lines.append("  â€¢ è€ƒè™‘å‹ç¼©æˆ–å½’æ¡£ä¸å¸¸ç”¨çš„æ–‡ä»¶")

        return "\n".join(report_lines)

    def _generate_json_report(self, sorted_files: List[Dict]) -> str:
        """ç”ŸæˆJSONæ ¼å¼æŠ¥å‘Š"""
        report_data = {
            'scan_info': {
                'scan_path': str(self.scan_path),
                'min_size_mb': self.min_size_bytes / (1024*1024),
                'scan_time': datetime.now().isoformat(),
                'statistics': self.scan_stats
            },
            'large_files': sorted_files
        }
        return json.dumps(report_data, ensure_ascii=False, indent=2)

    def save_report(self, report: str, filename: str = None) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"large_files_report_{timestamp}.txt"

        report_path = Path(filename)
        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write(report)
            return str(report_path.absolute())
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥ï¼š{e}")
            return None

    def run_scan(self) -> str:
        """æ‰§è¡Œå®Œæ•´æ‰«æ"""
        print(f"ğŸ” å¼€å§‹æ‰«æ {self.scan_path}...")
        print(f"ğŸ“ æŸ¥æ‰¾è¶…è¿‡ {self.min_size_bytes / (1024*1024):.0f}MB çš„æ–‡ä»¶...")

        self.scan_directory(self.scan_path)

        print(f"âœ… æ‰«æå®Œæˆï¼å‘ç° {self.scan_stats['large_files_count']} ä¸ªå¤§æ–‡ä»¶")

        return self.generate_report()


def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description='é¡¹ç›®å¤§æ–‡ä»¶æ‰«æå™¨')
    parser.add_argument('path', nargs='?', default='.',
                       help='è¦æ‰«æçš„è·¯å¾„ (é»˜è®¤: å½“å‰ç›®å½•)')
    parser.add_argument('-s', '--size', type=int, default=100,
                       help='æœ€å°æ–‡ä»¶å¤§å°(MB) (é»˜è®¤: 100)')
    parser.add_argument('-f', '--format', choices=['text', 'json'],
                       default='text', help='è¾“å‡ºæ ¼å¼ (é»˜è®¤: text)')
    parser.add_argument('-o', '--output', help='è¾“å‡ºæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-save', action='store_true',
                       help='ä¸ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶')

    args = parser.parse_args()

    # åˆ›å»ºæ‰«æå™¨å®ä¾‹
    scanner = LargeFileScanner(args.path, args.size)

    # æ‰§è¡Œæ‰«æ
    report = scanner.run_scan()

    # è¾“å‡ºæŠ¥å‘Š
    print("\n" + report)

    # ä¿å­˜æŠ¥å‘Š
    if not args.no_save:
        saved_path = scanner.save_report(report, args.output)
        if saved_path:
            print(f"\nğŸ’¾ æŠ¥å‘Šå·²ä¿å­˜åˆ°: {saved_path}")


if __name__ == "__main__":
    main()