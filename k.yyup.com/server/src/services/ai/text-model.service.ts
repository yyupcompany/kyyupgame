/**
 * æ–‡æœ¬æ¨¡å‹æœåŠ¡ - é€šè¿‡ç»Ÿä¸€AI BridgeæœåŠ¡
 * è‡ªåŠ¨è·¯ç”±AIè°ƒç”¨ï¼ˆæœ¬åœ°/ç»Ÿä¸€è®¤è¯ï¼‰
 */

import { unifiedAIBridge } from '../unified-ai-bridge.service';
import { AiBridgeMessage, AiBridgeMessageRole } from './bridge/ai-bridge.types';

/**
 * æ¶ˆæ¯è§’è‰²ç±»å‹
 */
export enum MessageRole {
  SYSTEM = 'system',
  USER = 'user',
  ASSISTANT = 'assistant',
  FUNCTION = 'function'
}

/**
 * æ¶ˆæ¯æ¥å£
 */
export interface Message {
  role: MessageRole | string;
  content: string;
  name?: string;
}

/**
 * æ–‡æœ¬ç”Ÿæˆé€‰é¡¹æ¥å£
 */
export interface TextGenerationOptions {
  model: string;
  messages: Message[];
  temperature?: number;
  maxTokens?: number;
  max_tokens?: number;
  topP?: number;
  frequencyPenalty?: number;
  presencePenalty?: number;
  stop?: string[];
  functions?: any[];
  functionCall?: string | { name: string };
  stream?: boolean;
}

/**
 * æ–‡æœ¬ç”Ÿæˆç»“æœæ¥å£
 */
export interface TextGenerationResult {
  id?: string;
  model?: string;
  content?: string;
  choices?: {
    index: number;
    message: Message;
    finishReason?: string;
    finish_reason?: string;
  }[];
  usage?: {
    promptTokens?: number;
    prompt_tokens?: number;
    completionTokens?: number;
    completion_tokens?: number;
    totalTokens?: number;
    total_tokens?: number;
  };
}

/**
 * æ–‡æœ¬æ¨¡å‹æœåŠ¡ç±» - ä»£ç†åˆ°ç»Ÿä¸€ç§Ÿæˆ·ç³»ç»Ÿ
 */
class TextModelService {
  constructor() {
    console.log('ğŸ”— [TextModelService] åˆå§‹åŒ–ï¼Œä»£ç†åˆ°ç»Ÿä¸€ç§Ÿæˆ·ç³»ç»Ÿ');
  }

  /**
   * ç”Ÿæˆæ–‡æœ¬ï¼ˆå…¼å®¹æ—§æ¥å£ï¼‰
   * @param userIdOrPromptOrOptions - ç”¨æˆ·IDï¼ˆæ•°å­—ï¼‰ã€æç¤ºæ–‡æœ¬ï¼ˆå­—ç¬¦ä¸²ï¼‰æˆ–é€‰é¡¹å¯¹è±¡
   * @param options - ç”Ÿæˆé€‰é¡¹
   */
  async generateText(userIdOrPromptOrOptions: string | number | Partial<TextGenerationOptions>, options?: Partial<TextGenerationOptions>): Promise<TextGenerationResult> {
    console.log('ğŸ“ [TextModelService] ç”Ÿæˆæ–‡æœ¬');

    // å…¼å®¹ä¸‰ç§è°ƒç”¨æ–¹å¼ï¼š
    // 1. generateText(options) - ç›´æ¥ä¼ é€‰é¡¹å¯¹è±¡
    // 2. generateText(userId, options) - æ–°æ¥å£
    // 3. generateText(prompt, options) - æ—§æ¥å£
    let messages: Message[];
    let finalOptions: Partial<TextGenerationOptions> = {};

    if (typeof userIdOrPromptOrOptions === 'object') {
      // ç›´æ¥ä¼ é€‰é¡¹å¯¹è±¡
      finalOptions = userIdOrPromptOrOptions;
      messages = finalOptions.messages || [{ role: MessageRole.USER, content: '' }];
    } else if (typeof userIdOrPromptOrOptions === 'number' || !isNaN(Number(userIdOrPromptOrOptions))) {
      // æ–°æ¥å£ï¼šuserId + options.messages
      finalOptions = options || {};
      messages = finalOptions.messages || [{ role: MessageRole.USER, content: '' }];
    } else {
      // æ—§æ¥å£ï¼šprompt ä½œä¸ºæ¶ˆæ¯å†…å®¹
      finalOptions = options || {};
      messages = [{ role: MessageRole.USER, content: userIdOrPromptOrOptions as string }];
    }

    const result = await this.generateChatCompletion({
      model: finalOptions.model || 'doubao-seed-1-6-flash-250715',
      messages,
      temperature: finalOptions.temperature,
      maxTokens: finalOptions.maxTokens || finalOptions.max_tokens,
    });

    return result;
  }

  /**
   * ç”ŸæˆèŠå¤©å®Œæˆ - æ ¸å¿ƒæ–¹æ³•
   * é€šè¿‡ç»Ÿä¸€AI Bridgeè‡ªåŠ¨è·¯ç”±åˆ°æœ¬åœ°/ç»Ÿä¸€è®¤è¯
   */
  async generateChatCompletion(options: TextGenerationOptions): Promise<TextGenerationResult> {
    console.log('ğŸ’¬ [TextModelService] èŠå¤©å®Œæˆè¯·æ±‚é€šè¿‡ç»Ÿä¸€AI Bridge');
    console.log(`   æ¨¡å‹: ${options.model}, æ¶ˆæ¯æ•°: ${options.messages?.length}`);

    try {
      // è½¬æ¢æ¶ˆæ¯æ ¼å¼ä¸º AiBridgeMessage
      const messages: AiBridgeMessage[] = options.messages.map(msg => ({
        role: msg.role as AiBridgeMessageRole,
        content: msg.content,
      }));

      // é€šè¿‡ç»Ÿä¸€AI Bridgeè°ƒç”¨ï¼ˆè‡ªåŠ¨è·¯ç”±ï¼‰
      const response = await unifiedAIBridge.chat({
        model: options.model,
        messages,
        temperature: options.temperature || 0.7,
        max_tokens: options.maxTokens || options.max_tokens || 2000,
      });

      // æå–å†…å®¹ - ç»Ÿä¸€æ ¼å¼
      const content = response.data?.content || response.data?.message || '';

      return {
        content,
        choices: [{
          index: 0,
          message: {
            role: MessageRole.ASSISTANT,
            content,
          },
        }],
        usage: response.data?.usage ? {
          promptTokens: response.data.usage.inputTokens,
          prompt_tokens: response.data.usage.inputTokens,
          completionTokens: response.data.usage.outputTokens,
          completion_tokens: response.data.usage.outputTokens,
          totalTokens: response.data.usage.totalTokens,
          total_tokens: response.data.usage.totalTokens,
        } : undefined,
      };
    } catch (error: any) {
      console.error('âŒ [TextModelService] èŠå¤©å®Œæˆè¯·æ±‚å¤±è´¥:', error.message);
      throw error;
    }
  }

  /**
   * æµå¼ç”Ÿæˆæ–‡æœ¬
   */
  async streamGenerateText(options: TextGenerationOptions): Promise<any> {
    console.log('ğŸŒŠ [TextModelService] æµå¼ç”Ÿæˆæ–‡æœ¬');

    const messages: AiBridgeMessage[] = options.messages.map(msg => ({
      role: msg.role as AiBridgeMessageRole,
      content: msg.content,
    }));

    return unifiedAIBridge.streamChat({
      model: options.model,
      messages,
      temperature: options.temperature || 0.7,
      max_tokens: options.maxTokens || options.max_tokens || 2000,
    });
  }

  /**
   * è®¡ç®—æ–‡æœ¬ä¸­çš„tokenæ•°é‡
   */
  countTokens(text: string): number {
    // ç®€å•ä¼°ç®—ï¼šæ¯4ä¸ªå­—ç¬¦çº¦ä¸º1ä¸ªtoken
    return Math.ceil(text.length / 4);
  }
}

// åˆ›å»ºå•ä¾‹å¹¶å¯¼å‡º
const textModelService = new TextModelService();
export default textModelService;
export { textModelService };
