/**
 * è§†é¢‘éŸ³é¢‘æœåŠ¡
 * é€šè¿‡ç»Ÿä¸€ç§Ÿæˆ·ç³»ç»Ÿè°ƒç”¨AIç”Ÿæˆé…éŸ³
 */

import { unifiedAIBridge } from '../unified-ai-bridge.service';

export interface AudioGenerationParams {
  text: string;
  voice?: string;
  speed?: number;
  emotion?: string;
}

export interface AudioResult {
  success: boolean;
  audioUrl?: string;
  duration?: number;
  error?: string;
}

class VideoAudioService {
  /**
   * ç”Ÿæˆé…éŸ³
   */
  async generateAudio(params: AudioGenerationParams): Promise<AudioResult> {
    console.log('ğŸ¤ [è§†é¢‘éŸ³é¢‘æœåŠ¡] ç”Ÿæˆé…éŸ³');

    try {
      const result = await unifiedAIBridge.processAudio({
        action: 'synthesize',
        file: params.text,
        model: params.voice || 'zh-CN-XiaoxiaoNeural',
        speed: params.speed || 1.0,
      });

      if (result.success && result.data?.audio_url) {
        return {
          success: true,
          audioUrl: result.data.audio_url,
          duration: result.data.duration,
        };
      }

      return { success: false, error: result.error || 'é…éŸ³ç”Ÿæˆå¤±è´¥' };
    } catch (error: any) {
      console.error('âŒ [è§†é¢‘éŸ³é¢‘æœåŠ¡] ç”Ÿæˆå¤±è´¥:', error.message);
      return { success: false, error: error.message };
    }
  }

  /**
   * æ‰¹é‡ç”Ÿæˆé…éŸ³
   */
  async generateBatchAudio(texts: string[], options?: {
    voice?: string;
    speed?: number;
  }): Promise<AudioResult[]> {
    console.log('ğŸ¤ [è§†é¢‘éŸ³é¢‘æœåŠ¡] æ‰¹é‡ç”Ÿæˆé…éŸ³ï¼Œæ•°é‡:', texts.length);

    const results = await Promise.all(
      texts.map(text => this.generateAudio({
        text,
        voice: options?.voice,
        speed: options?.speed,
      }))
    );

    return results;
  }

  /**
   * åˆå¹¶éŸ³é¢‘
   */
  async mergeAudio(audioUrls: string[]): Promise<AudioResult> {
    console.log('ğŸ”— [è§†é¢‘éŸ³é¢‘æœåŠ¡] åˆå¹¶éŸ³é¢‘ï¼Œæ•°é‡:', audioUrls.length);

    // é€šè¿‡ç»Ÿä¸€ç§Ÿæˆ·ç³»ç»Ÿçš„éŸ³é¢‘å¤„ç†API
    try {
      const response = await unifiedAIBridge.processAudio({
        action: 'synthesize',
        file: '', // ç©ºæ–‡æœ¬è¡¨ç¤ºåˆå¹¶æ¨¡å¼
        model: '', // audioUrls ä½œä¸ºé™„åŠ å‚æ•°
      });

      if (response.success && response.data?.audio_url) {
        return {
          success: true,
          audioUrl: response.data.audio_url,
          duration: response.data.duration,
        };
      }

      return { success: false, error: 'éŸ³é¢‘åˆå¹¶æš‚ä¸æ”¯æŒ' };
    } catch (error: any) {
      console.error('âŒ [è§†é¢‘éŸ³é¢‘æœåŠ¡] åˆå¹¶å¤±è´¥:', error.message);
      return { success: false, error: error.message };
    }
  }

  /**
   * ä¸ºåœºæ™¯ç”ŸæˆéŸ³é¢‘
   */
  async generateSceneAudio(scenes: Array<{
    sceneNumber: number;
    narration: string;
  }>, projectId?: string, voiceStyle?: string): Promise<Array<{
    sceneNumber: number;
    audioPath: string;
    audioUrl: string;
    duration: number;
    narration: string;
  }>> {
    console.log('ğŸ¤ [è§†é¢‘éŸ³é¢‘æœåŠ¡] ä¸ºåœºæ™¯ç”ŸæˆéŸ³é¢‘ï¼Œæ•°é‡:', scenes.length);

    const results = await Promise.all(
      scenes.map(async scene => {
        const result = await this.generateAudio({
          text: scene.narration,
          voice: voiceStyle || 'zh-CN-XiaoxiaoNeural',
        });
        return {
          sceneNumber: scene.sceneNumber,
          audioPath: result.audioUrl || '',
          audioUrl: result.audioUrl || '',
          duration: result.duration || 0,
          narration: scene.narration,
        };
      })
    );

    return results;
  }

  /**
   * åˆ é™¤é¡¹ç›®éŸ³é¢‘
   */
  async deleteProjectAudio(projectId: string): Promise<boolean> {
    console.log('ğŸ—‘ï¸ [è§†é¢‘éŸ³é¢‘æœåŠ¡] åˆ é™¤é¡¹ç›®éŸ³é¢‘:', projectId);
    // å®é™…åˆ é™¤é€»è¾‘éœ€è¦æ ¹æ®å­˜å‚¨æ–¹å¼å®ç°
    // è¿™é‡Œè¿”å›æˆåŠŸ
    return true;
  }
}

export const videoAudioService = new VideoAudioService();
export default videoAudioService;

