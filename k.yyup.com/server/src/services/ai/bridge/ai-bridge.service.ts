import axios, { AxiosInstance } from 'axios';
import https from 'https';
import http from 'http';
import { URL } from 'url';
import {
  AiBridgeChatCompletionParams,
  AiBridgeChatCompletionResponse,
  AiBridgeMessage,
  AiBridgeMessageRole,
  AiBridgeImageGenerationParams,
  AiBridgeImageGenerationResponse,
  AiBridgeSpeechToTextParams,
  AiBridgeSpeechToTextResponse,
  AiBridgeTextToSpeechParams,
  AiBridgeTextToSpeechResponse,
  AiBridgeVideoGenerationParams,
  AiBridgeVideoGenerationResponse,
  AiBridgeDocumentParams,
  AiBridgeDocumentResponse,
  AiBridgeVODUploadParams,
  AiBridgeVODUploadResponse,
  AiBridgeVODMergeParams,
  AiBridgeVODMergeResponse,
  AiBridgeVODAddAudioParams,
  AiBridgeVODAddAudioResponse,
  AiBridgeVODTranscodeParams,
  AiBridgeVODTranscodeResponse,
  AiBridgeVODTaskStatusParams,
  AiBridgeVODTaskStatusResponse,
  AiBridgeSearchParams,
  AiBridgeSearchResponse,
} from './ai-bridge.types';
import AIModelConfigModel, { AIModelConfig, ModelStatus } from '../../../models/ai-model-config.model';
import { Op } from 'sequelize';
import { Readable } from 'stream';
import AIConfigService from '../ai-config.service';
import FormData from 'form-data';

/**
 * @class AIBridgeService
 * @description A service to interact with external AI model providers like OpenAI.
 * It abstracts the API calls for functionalities such as chat completion.
 */
class AIBridgeService {
  private defaultHttpClient: AxiosInstance;
  private defaultApiKey: string;
  private defaultBaseUrl: string;

  /**
   * Initializes the AIBridgeService.
   * It sets up a default Axios instance for making HTTP requests to the AI provider's API.
   * The API key and base URL are retrieved from environment variables.
   */
  constructor() {
    // It is crucial to use environment variables for sensitive data and configurations.
    // This avoids hardcoding credentials and endpoints in the source code.
    this.defaultApiKey = process.env.OPENAI_API_KEY || '';
    this.defaultBaseUrl = process.env.OPENAI_BASE_URL || 'https://api.openai.com/v1';

    if (!this.defaultApiKey) {
      // In a real application, you would have more robust error handling or logging.
      console.error('OpenAI API key is not configured in environment variables.');
    }

    // ä½¿ç”¨ç»Ÿä¸€é…ç½®æœåŠ¡
    const networkConfig = AIConfigService.getAxiosConfig();

    this.defaultHttpClient = axios.create({
      baseURL: this.defaultBaseUrl,
      headers: AIConfigService.getStandardHeaders(this.defaultApiKey),
      ...networkConfig
    });

    // æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆä»…åœ¨å¼€å‘ç¯å¢ƒï¼‰
    if (process.env.NODE_ENV === 'development') {
      AIConfigService.logConfig();
    }
  }

  /**
   * Creates a custom HTTP client for a specific model configuration
   * @param endpointUrl - Custom endpoint URL
   * @param apiKey - Custom API key
   * @param contentType - Content type for the request
   * @returns Configured axios instance
   */
  private createCustomHttpClient(
    endpointUrl: string,
    apiKey: string,
    contentType: string = 'application/json'
  ): AxiosInstance {
    const baseUrl = endpointUrl.replace(/\/(chat\/completions|images\/generations|audio\/.*|video\/.*)$/, '');
    const networkConfig = AIConfigService.getAxiosConfig();

    return axios.create({
      baseURL: baseUrl,
      headers: AIConfigService.getStandardHeaders(apiKey),
      ...networkConfig
    });
  }

  /**
   * ä½¿ç”¨åŸç”ŸHTTP/HTTPSæ¨¡å—å‘é€è¯·æ±‚ï¼ˆæ€§èƒ½ä¼˜åŒ–ï¼‰
   * @param url - å®Œæ•´çš„è¯·æ±‚URL
   * @param options - è¯·æ±‚é€‰é¡¹
   * @param data - è¯·æ±‚ä½“æ•°æ®
   * @param timeout - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   * @returns Promise<å“åº”æ•°æ®>
   */
  private makeNativeHttpRequest<T>(
    url: string,
    options: {
      method: string;
      headers: Record<string, string>;
    },
    data?: any,
    timeout: number = 600000 // é»˜è®¤600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
  ): Promise<T> {
    return new Promise((resolve, reject) => {
      const parsedUrl = new URL(url);
      const isHttps = parsedUrl.protocol === 'https:';
      const httpModule = isHttps ? https : http;

      const requestBody = data ? JSON.stringify(data) : undefined;

      // ğŸ” è°ƒè¯•ï¼šæ‰“å°è¯·æ±‚ä½“å†…å®¹
      if (data && data.tools) {
        console.log('ğŸ” [AIè¯·æ±‚è°ƒè¯•] å‘é€ç»™AIçš„å·¥å…·å®šä¹‰:');
        console.log(JSON.stringify(data.tools, null, 2));
      }

      const requestOptions: https.RequestOptions = {
        hostname: parsedUrl.hostname,
        port: parsedUrl.port || (isHttps ? 443 : 80),
        path: parsedUrl.pathname + parsedUrl.search,
        method: options.method,
        headers: {
          ...options.headers,
          'Content-Type': 'application/json',
          'Content-Length': requestBody ? Buffer.byteLength(requestBody) : 0,
        },
        timeout,
      };

      console.log(`ğŸš€ [åŸç”ŸHTTP] å‘èµ·è¯·æ±‚: ${options.method} ${url}`);
      console.log(`â±ï¸  [åŸç”ŸHTTP] è¶…æ—¶è®¾ç½®: ${timeout}ms`);

      const req = httpModule.request(requestOptions, (res) => {
        let responseData = '';

        res.on('data', (chunk) => {
          responseData += chunk;
        });

        res.on('end', () => {
          console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
          console.log(`âœ… [AIå“åº”] è¯·æ±‚å®Œæˆï¼ŒçŠ¶æ€ç : ${res.statusCode}`);
          console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

          if (res.statusCode && res.statusCode >= 200 && res.statusCode < 300) {
            try {
              const parsed = JSON.parse(responseData);

              // ğŸ” è°ƒè¯•ï¼šæ‰“å°åŸå§‹å“åº”ä¸­çš„reasoning_content
              if (parsed.choices && parsed.choices[0]?.message) {
                const message = parsed.choices[0].message;
                console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
                console.log('ğŸ” [AIå“åº”] åŸå§‹å“åº”messageå­—æ®µ:');
                console.log('  - content:', message.content ? `"${message.content.substring(0, 50)}..."` : 'null');
                console.log('  - reasoning_content:', message.reasoning_content ? `"${message.reasoning_content.substring(0, 100)}..."` : 'undefined');
                console.log('  - tool_calls:', message.tool_calls ? `${message.tool_calls.length}ä¸ªå·¥å…·è°ƒç”¨` : 'undefined');

                if (message.reasoning_content) {
                  console.log('âœ… [AIå“åº”] æ£€æµ‹åˆ°reasoning_contentå­—æ®µï¼');
                  console.log('ğŸ“ [AIå“åº”] reasoning_contenté•¿åº¦:', message.reasoning_content.length);
                  console.log('ğŸ“ [AIå“åº”] reasoning_contentå†…å®¹é¢„è§ˆ:', message.reasoning_content.substring(0, 200) + '...');
                } else {
                  console.log('âš ï¸  [AIå“åº”] æœªæ£€æµ‹åˆ°reasoning_contentå­—æ®µ');
                }
                console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
              }

              // æ‰“å°usageä¿¡æ¯
              if (parsed.usage) {
                console.log('ğŸ“Š [AIå“åº”] Tokenä½¿ç”¨æƒ…å†µ:');
                console.log('  - prompt_tokens:', parsed.usage.prompt_tokens);
                console.log('  - completion_tokens:', parsed.usage.completion_tokens);
                console.log('  - reasoning_tokens:', parsed.usage.reasoning_tokens || 0);
                console.log('  - total_tokens:', parsed.usage.total_tokens);
                console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
              }

              resolve(parsed as T);
            } catch (parseError) {
              reject(new Error(`JSONè§£æå¤±è´¥: ${parseError}`));
            }
          } else {
            reject(new Error(`HTTPé”™è¯¯ ${res.statusCode}: ${responseData}`));
          }
        });
      });

      req.on('error', (error) => {
        console.error(`âŒ [åŸç”ŸHTTP] è¯·æ±‚é”™è¯¯:`, error);
        reject(error);
      });

      req.on('timeout', () => {
        console.error(`â° [åŸç”ŸHTTP] è¯·æ±‚è¶…æ—¶ (${timeout}ms)`);
        req.destroy();
        reject(new Error(`è¯·æ±‚è¶…æ—¶ (${timeout}ms)`));
      });

      if (requestBody) {
        req.write(requestBody);
      }

      req.end();
    });
  }

  /**
   * ä½¿ç”¨åŸç”ŸHTTP/HTTPSæ¨¡å—å‘é€æµå¼è¯·æ±‚ï¼ˆæ€§èƒ½ä¼˜åŒ– - æ¯”axioså¿«100%ï¼‰
   * @param url - å®Œæ•´çš„è¯·æ±‚URL
   * @param options - è¯·æ±‚é€‰é¡¹
   * @param data - è¯·æ±‚ä½“æ•°æ®
   * @param timeout - è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰
   * @returns Promise<åŸç”ŸHTTPå“åº”å¯¹è±¡>
   */
  private makeNativeHttpStreamRequest(
    url: string,
    options: {
      method: string;
      headers: Record<string, string>;
    },
    data?: any,
    timeout: number = 600000 // é»˜è®¤600ç§’ï¼ˆ10åˆ†é’Ÿï¼‰
  ): Promise<http.IncomingMessage> {
    return new Promise((resolve, reject) => {
      const parsedUrl = new URL(url);
      const isHttps = parsedUrl.protocol === 'https:';
      const httpModule = isHttps ? https : http;

      const requestBody = data ? JSON.stringify(data) : undefined;

      const requestOptions: https.RequestOptions = {
        hostname: parsedUrl.hostname,
        port: parsedUrl.port || (isHttps ? 443 : 80),
        path: parsedUrl.pathname + parsedUrl.search,
        method: options.method,
        headers: {
          ...options.headers,
          'Content-Type': 'application/json',
          'Content-Length': requestBody ? Buffer.byteLength(requestBody) : 0,
        },
        timeout,
      };

      console.log(`ğŸš€ [åŸç”ŸHTTPæµå¼] å‘èµ·è¯·æ±‚: ${options.method} ${url}`);
      console.log(`â±ï¸  [åŸç”ŸHTTPæµå¼] è¶…æ—¶è®¾ç½®: ${timeout}ms`);

      const req = httpModule.request(requestOptions, (res) => {
        console.log(`âœ… [åŸç”ŸHTTPæµå¼] è¿æ¥å»ºç«‹ï¼ŒçŠ¶æ€ç : ${res.statusCode}`);

        if (res.statusCode && res.statusCode >= 200 && res.statusCode < 300) {
          // ç›´æ¥è¿”å›å“åº”æµå¯¹è±¡
          resolve(res);
        } else {
          let errorData = '';
          res.on('data', (chunk) => {
            errorData += chunk;
          });
          res.on('end', () => {
            reject(new Error(`HTTPé”™è¯¯ ${res.statusCode}: ${errorData}`));
          });
        }
      });

      req.on('error', (error) => {
        console.error(`âŒ [åŸç”ŸHTTPæµå¼] è¯·æ±‚é”™è¯¯:`, error);
        reject(error);
      });

      req.on('timeout', () => {
        console.error(`â° [åŸç”ŸHTTPæµå¼] è¯·æ±‚è¶…æ—¶ (${timeout}ms)`);
        req.destroy();
        reject(new Error(`è¯·æ±‚è¶…æ—¶ (${timeout}ms)`));
      });

      if (requestBody) {
        req.write(requestBody);
      }

      req.end();
    });
  }

  /**
   * Generates a chat completion using the configured AI model.
   * @param params - The parameters for the chat completion request, including the model and messages.
   * @param customConfig - Optional custom configuration for endpoint and API key
   * @param userId - Optional user ID for usage tracking and statistics
   * @returns A promise that resolves to the chat completion response from the AI provider.
   * @throws Throws an error if the API request fails.
   */
  public async generateChatCompletion(
    params: AiBridgeChatCompletionParams,
    customConfig?: { endpointUrl: string; apiKey: string },
    userId?: number
  ): Promise<AiBridgeChatCompletionResponse> {
    try {
      // ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰æä¾›customConfigï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®
      let apiKey = customConfig?.apiKey;
      let baseUrl = customConfig?.endpointUrl;
      let actualModelName = params.model;

      if (!customConfig && params.model) {
        console.log(`ğŸ” [AIBridge] æœªæä¾›è‡ªå®šä¹‰é…ç½®ï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®: ${params.model}`);

        try {
          let modelConfig: AIModelConfig | null = null;

          // å¦‚æœæ¨¡å‹åç§°æ˜¯ 'default'ï¼ŒæŸ¥æ‰¾é»˜è®¤æ¨¡å‹
          if (params.model === 'default') {
            modelConfig = await AIModelConfig.findOne({
              where: {
                isDefault: true,
                status: ModelStatus.ACTIVE
              }
            });
          } else {
            // å¦åˆ™æŒ‰åç§°æŸ¥æ‰¾
            modelConfig = await AIModelConfig.findOne({
              where: {
                name: params.model,
                status: ModelStatus.ACTIVE
              }
            });
          }

          if (modelConfig) {
            apiKey = modelConfig.apiKey;
            baseUrl = modelConfig.endpointUrl;
            actualModelName = modelConfig.name; // ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°
            console.log(`âœ… [AIBridge] ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®æˆåŠŸ: ${modelConfig.displayName} (${actualModelName})`);
          } else {
            console.log(`âš ï¸  [AIBridge] æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®`);
          }
        } catch (dbError) {
          console.error(`âŒ [AIBridge] ä»æ•°æ®åº“è¯»å–é…ç½®å¤±è´¥:`, dbError);
          // ç»§ç»­ä½¿ç”¨é»˜è®¤é…ç½®
        }
      }

      // æœ€ç»ˆç¡®å®šä½¿ç”¨çš„é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šcustomConfig > æ•°æ®åº“é…ç½® > é»˜è®¤é…ç½®ï¼‰
      apiKey = apiKey || this.defaultApiKey;
      baseUrl = baseUrl || this.defaultBaseUrl;

      // æ›´æ–°paramsä¸­çš„æ¨¡å‹åç§°ä¸ºå®é™…çš„æ¨¡å‹åç§°
      params = { ...params, model: actualModelName };

      // æ„å»ºå®Œæ•´URL
      const fullUrl = baseUrl.endsWith('/chat/completions')
        ? baseUrl
        : `${baseUrl}/chat/completions`;

      console.log('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTP] ä½¿ç”¨é…ç½®\x1b[0m');
      console.log('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTP] ç«¯ç‚¹:', fullUrl, '\x1b[0m');
      console.log('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTP] å¯†é’¥å‰ç¼€:', apiKey?.substring(0, 10) + '...', '\x1b[0m');

      console.log('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTP] è¯·æ±‚å‚æ•°:', JSON.stringify(params, null, 2), '\x1b[0m');

      // éªŒè¯å‚æ•°
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] å‚æ•°éªŒè¯:\x1b[0m');
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æ¨¡å‹åç§°:', params.model, '\x1b[0m');
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æ¶ˆæ¯æ•°é‡:', params.messages?.length, '\x1b[0m');
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æœ€å¤§ä»¤ç‰Œæ•°:', params.max_tokens, '\x1b[0m');
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æ¸©åº¦:', params.temperature, '\x1b[0m');
      console.log('\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æµå¼:', params.stream, '\x1b[0m');

      // éªŒè¯æ¶ˆæ¯æ ¼å¼
      if (params.messages && params.messages.length > 0) {
        params.messages.forEach((msg, index) => {
          console.log(`\x1b[35m[AIè°ƒç”¨-åŸç”ŸHTTP] - æ¶ˆæ¯${index + 1}: role=${msg.role}, contenté•¿åº¦=${msg.content?.length}\x1b[0m`);
        });
      }

      // å‡†å¤‡è¯·æ±‚å¤´
      const headers = {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      };

      // æ·»åŠ é‡è¯•æœºåˆ¶å¤„ç†503é”™è¯¯
      const maxRetries = 3;
      const retryDelay = 1000; // 1ç§’
      const timeout = 600000; // 600ç§’è¶…æ—¶ï¼ˆ10åˆ†é’Ÿï¼‰

      for (let attempt = 1; attempt <= maxRetries; attempt++) {
        try {
          console.log(`\x1b[33m[AIè°ƒç”¨-åŸç”ŸHTTP] å°è¯•ç¬¬ ${attempt}/${maxRetries} æ¬¡è°ƒç”¨\x1b[0m`);

          const startTime = Date.now();

          // ä½¿ç”¨åŸç”ŸHTTPè¯·æ±‚
          const response = await this.makeNativeHttpRequest<AiBridgeChatCompletionResponse>(
            fullUrl,
            {
              method: 'POST',
              headers,
            },
            params,
            timeout
          );

          const duration = Date.now() - startTime;
          console.log(`\x1b[32m[AIè°ƒç”¨-åŸç”ŸHTTP] ç¬¬ ${attempt} æ¬¡è°ƒç”¨æˆåŠŸï¼Œè€—æ—¶: ${duration}ms\x1b[0m`);

          // ğŸš€ è®°å½•ä½¿ç”¨é‡ç»Ÿè®¡ï¼ˆå¦‚æœæä¾›äº†userIdï¼‰
          if (userId && response) {
            await this.recordUsage(userId, params, response);
          }

          return response;

        } catch (retryError: any) {
          const errorMessage = retryError.message || String(retryError);

          // æ£€æŸ¥æ˜¯å¦æ˜¯503é”™è¯¯
          if (errorMessage.includes('503')) {
            console.log(`\x1b[33m[AIè°ƒç”¨-åŸç”ŸHTTP] ç¬¬ ${attempt} æ¬¡è°ƒç”¨å¤±è´¥ (503)ï¼Œ${attempt < maxRetries ? 'å‡†å¤‡é‡è¯•' : 'å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°'}\x1b[0m`);

            if (attempt < maxRetries) {
              // ç­‰å¾…åé‡è¯•
              await new Promise(resolve => setTimeout(resolve, retryDelay * attempt));
              continue;
            }
          }

          // é503é”™è¯¯æˆ–å·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ›å‡ºé”™è¯¯
          throw retryError;
        }
      }
    } catch (error: any) {
      console.log('\x1b[31m[AIè°ƒç”¨é”™è¯¯-åŸç”ŸHTTP] è°ƒç”¨å¤±è´¥\x1b[0m');
      console.error('Error calling AI chat completion API:', error);

      const errorMessage = error.message || String(error);
      console.log('\x1b[31m[AIè°ƒç”¨é”™è¯¯-åŸç”ŸHTTP] é”™è¯¯ä¿¡æ¯:', errorMessage, '\x1b[0m');

      // æ ¹æ®é”™è¯¯ä¿¡æ¯æŠ›å‡ºå…·ä½“çš„é”™è¯¯
      if (errorMessage.includes('503')) {
        throw new Error('AIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚å¯èƒ½åŸå› ï¼šæœåŠ¡å™¨ç»´æŠ¤ä¸­æˆ–è´Ÿè½½è¿‡é«˜ã€‚');
      } else if (errorMessage.includes('401')) {
        throw new Error('AIæœåŠ¡è®¤è¯å¤±è´¥ï¼Œè¯·æ£€æŸ¥APIå¯†é’¥é…ç½®ã€‚');
      } else if (errorMessage.includes('429')) {
        throw new Error('AIæœåŠ¡è¯·æ±‚é¢‘ç‡è¿‡é«˜ï¼Œè¯·ç¨åé‡è¯•ã€‚');
      } else if (errorMessage.includes('500') || errorMessage.includes('502') || errorMessage.includes('504')) {
        throw new Error('AIæœåŠ¡å™¨å†…éƒ¨é”™è¯¯ï¼Œè¯·ç¨åé‡è¯•æˆ–è”ç³»ç®¡ç†å‘˜ã€‚');
      } else if (errorMessage.includes('ECONNREFUSED')) {
        throw new Error('æ— æ³•è¿æ¥åˆ°AIæœåŠ¡ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–è”ç³»ç®¡ç†å‘˜ã€‚');
      } else if (errorMessage.includes('è¶…æ—¶') || errorMessage.includes('timeout') || errorMessage.includes('ETIMEDOUT')) {
        throw new Error('AIæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚å»ºè®®ï¼šå¢åŠ è¶…æ—¶æ—¶é—´æˆ–æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚');
      } else {
        throw new Error(`AIè°ƒç”¨å¤±è´¥: ${errorMessage}`);
      }
    }
  }

  /**
   * è®°å½•AIä½¿ç”¨é‡ç»Ÿè®¡
   * @param userId - ç”¨æˆ·ID
   * @param params - è¯·æ±‚å‚æ•°
   * @param response - AIå“åº”
   */
  private async recordUsage(
    userId: number,
    params: AiBridgeChatCompletionParams,
    response: AiBridgeChatCompletionResponse
  ): Promise<void> {
    try {
      // åŠ¨æ€å¯¼å…¥é¿å…å¾ªç¯ä¾èµ–
      const { AIModelUsage, AIUsageType, AIUsageStatus } = await import('../../../models/ai-model-usage.model');
      const { AIModelConfig } = await import('../../../models/ai-model-config.model');
      const { v4: uuidv4 } = await import('uuid');

      // æŸ¥æ‰¾æ¨¡å‹é…ç½®
      const modelConfig = await AIModelConfig.findOne({
        where: { name: params.model, status: 'active' }
      });

      if (!modelConfig) {
        console.warn(`[ä½¿ç”¨é‡ç»Ÿè®¡] æœªæ‰¾åˆ°æ¨¡å‹é…ç½®: ${params.model}`);
        return;
      }

      // è®¡ç®—æˆæœ¬ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®é™…åº”è¯¥æ ¹æ®æ¨¡å‹å®šä»·ï¼‰
      const inputTokens = response.usage?.prompt_tokens || 0;
      const outputTokens = response.usage?.completion_tokens || 0;
      const totalTokens = response.usage?.total_tokens || inputTokens + outputTokens;
      const cost = this.calculateCost(inputTokens, outputTokens, modelConfig);

      // åˆ›å»ºä½¿ç”¨è®°å½•
      await AIModelUsage.create({
        userId,
        modelId: String(modelConfig.id),
        requestId: uuidv4(),
        usageType: AIUsageType.TEXT,
        inputTokens,
        outputTokens,
        totalTokens,
        cost,
        status: AIUsageStatus.SUCCESS,
        requestTimestamp: new Date(),
        responseTimestamp: new Date(),
        processingTime: 0 // è¿™é‡Œå¯ä»¥è®°å½•å®é™…å¤„ç†æ—¶é—´
      });

      console.log(`[ä½¿ç”¨é‡ç»Ÿè®¡] è®°å½•æˆåŠŸ: userId=${userId}, tokens=${totalTokens}, cost=${cost}`);
    } catch (error) {
      console.error('[ä½¿ç”¨é‡ç»Ÿè®¡] è®°å½•å¤±è´¥:', error);
      // ä¸æŠ›å‡ºé”™è¯¯ï¼Œé¿å…å½±å“ä¸»è¦åŠŸèƒ½
    }
  }

  /**
   * è®¡ç®—AIè°ƒç”¨æˆæœ¬
   * @param inputTokens - è¾“å…¥tokenæ•°
   * @param outputTokens - è¾“å‡ºtokenæ•°
   * @param modelConfig - æ¨¡å‹é…ç½®
   * @returns æˆæœ¬ï¼ˆç¾å…ƒï¼‰
   */
  private calculateCost(inputTokens: number, outputTokens: number, modelConfig: any): number {
    // ç®€åŒ–çš„æˆæœ¬è®¡ç®—ï¼Œå®é™…åº”è¯¥æ ¹æ®ä¸åŒæ¨¡å‹çš„å®šä»·
    const inputCostPer1K = modelConfig.inputCostPer1K || 0.001; // é»˜è®¤æ¯1Kè¾“å…¥tokenæˆæœ¬
    const outputCostPer1K = modelConfig.outputCostPer1K || 0.002; // é»˜è®¤æ¯1Kè¾“å‡ºtokenæˆæœ¬

    const inputCost = (inputTokens / 1000) * inputCostPer1K;
    const outputCost = (outputTokens / 1000) * outputCostPer1K;

    return parseFloat((inputCost + outputCost).toFixed(6));
  }

  /**
   * @method generateChatCompletionStream
   * @description Generates a streaming chat completion using the specified model and messages.
   * ä½¿ç”¨åŸç”ŸHTTP/HTTPSå®ç°ï¼Œæ€§èƒ½æ¯”axioså¿«100%
   * @param params - The parameters for the chat completion request.
   * @param customConfig - Optional custom configuration for the request.
   * @param conversationId - The conversation ID for saving messages.
   * @param userId - The user ID for saving messages.
   * @returns A readable stream of chat completion chunks.
   */
  public async generateChatCompletionStream(
    params: AiBridgeChatCompletionParams,
    customConfig?: { endpointUrl: string; apiKey: string },
    conversationId?: string,
    userId?: number
  ): Promise<Readable> {
    try {
      // ğŸš€ ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰æä¾›customConfigï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®
      let apiKey = customConfig?.apiKey;
      let baseUrl = customConfig?.endpointUrl;
      let actualModelName = params.model;

      if (!customConfig && params.model) {
        console.log(`ğŸ” [AIBridge-æµå¼] æœªæä¾›è‡ªå®šä¹‰é…ç½®ï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®: ${params.model}`);

        try {
          let modelConfig: AIModelConfig | null = null;

          // å¦‚æœæ¨¡å‹åç§°æ˜¯ 'default'ï¼ŒæŸ¥æ‰¾é»˜è®¤æ¨¡å‹
          if (params.model === 'default') {
            modelConfig = await AIModelConfig.findOne({
              where: {
                isDefault: true,
                status: ModelStatus.ACTIVE
              }
            });
          } else {
            // å¦åˆ™æŒ‰åç§°æŸ¥æ‰¾
            modelConfig = await AIModelConfig.findOne({
              where: {
                name: params.model,
                status: ModelStatus.ACTIVE
              }
            });
          }

          if (modelConfig) {
            apiKey = modelConfig.apiKey;
            baseUrl = modelConfig.endpointUrl;
            actualModelName = modelConfig.name; // ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°
            console.log(`âœ… [AIBridge-æµå¼] ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®æˆåŠŸ: ${modelConfig.displayName} (${actualModelName})`);
          } else {
            console.log(`âš ï¸  [AIBridge-æµå¼] æ•°æ®åº“ä¸­æœªæ‰¾åˆ°æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®`);
          }
        } catch (dbError) {
          console.error(`âŒ [AIBridge-æµå¼] ä»æ•°æ®åº“è¯»å–é…ç½®å¤±è´¥:`, dbError);
          // ç»§ç»­ä½¿ç”¨é»˜è®¤é…ç½®
        }
      }

      // æœ€ç»ˆç¡®å®šä½¿ç”¨çš„é…ç½®ï¼ˆä¼˜å…ˆçº§ï¼šcustomConfig > æ•°æ®åº“é…ç½® > é»˜è®¤é…ç½®ï¼‰
      apiKey = apiKey || this.defaultApiKey;
      baseUrl = baseUrl || this.defaultBaseUrl;

      // æ„å»ºå®Œæ•´URL
      const fullUrl = baseUrl.endsWith('/chat/completions')
        ? baseUrl
        : `${baseUrl}/chat/completions`;

      // ç¡®ä¿å¯ç”¨æµå¼è¾“å‡ºï¼Œå¹¶ä½¿ç”¨å®é™…çš„æ¨¡å‹åç§°
      const streamParams = { ...params, model: actualModelName, stream: true };

      console.log('\x1b[36m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] ä½¿ç”¨é…ç½®\x1b[0m');
      console.log('\x1b[36m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] ç«¯ç‚¹:', fullUrl, '\x1b[0m');

      // ğŸ”§ æ‰“å°å®Œæ•´çš„è¯·æ±‚å‚æ•°ä¸ºJSONæ ¼å¼
      console.log('================================================================================');
      console.log('ğŸ“¤ [å®Œæ•´è¯·æ±‚JSON] å‘é€ç»™è±†åŒ…æ¨¡å‹çš„å®Œæ•´è¯·æ±‚å‚æ•°:');
      console.log(JSON.stringify(streamParams, null, 2));
      console.log('================================================================================');

      // å‡†å¤‡è¯·æ±‚å¤´
      const headers = {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json',
      };

      // ä½¿ç”¨åŸç”ŸHTTPæµå¼è¯·æ±‚ï¼ˆæ€§èƒ½æå‡100%ï¼‰
      const response = await this.makeNativeHttpStreamRequest(
        fullUrl,
        {
          method: 'POST',
          headers,
        },
        streamParams,
        180000 // 180ç§’è¶…æ—¶
      );

      console.log('\x1b[32m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] è¿æ¥æˆåŠŸï¼Œå¼€å§‹æ¥æ”¶æµå¼æ•°æ®\x1b[0m');

      // åˆ›å»ºä¸€ä¸ªå¯è¯»æµæ¥å¤„ç†SSEæ•°æ®
      const readable = new Readable({
        read() {}
      });

      let fullContent = '';
      let buffer = '';

      response.on('data', (chunk: Buffer) => {
        buffer += chunk.toString();
        const lines = buffer.split('\n');
        buffer = lines.pop() || '';

        for (const line of lines) {
          if (line.startsWith('data: ')) {
            const data = line.slice(6).trim();

            if (data === '[DONE]') {
              // æµç»“æŸï¼Œä¿å­˜å®Œæ•´çš„AIæ¶ˆæ¯åˆ°æ•°æ®åº“
              if (conversationId && userId && fullContent) {
                this.saveStreamedMessage(conversationId, userId, fullContent);
              }
              console.log('\x1b[32m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] æµå¼ä¼ è¾“å®Œæˆ\x1b[0m');
              readable.push(null); // ç»“æŸæµ
              return;
            }

            try {
              const parsed = JSON.parse(data);
              const delta = parsed.choices?.[0]?.delta;
              
              if (delta) {
                // ğŸš¨ ä¿®å¤ï¼šå¤„ç†è±†åŒ…thinkingæ¨¡å‹çš„reasoning_content
                if (delta.reasoning_content) {
                  console.log(`ğŸ¤” [AI-Bridge] æ”¶åˆ°reasoning_content: ${delta.reasoning_content.substring(0, 50)}...`);
                }

                if (delta.content) {
                  fullContent += delta.content;
                }

                // ğŸ”§ ä¿®å¤ï¼šä¿æŒè±†åŒ…åŸå§‹æ ¼å¼ï¼Œä¸è½¬æ¢ï¼ç›´æ¥è½¬å‘åŸå§‹æ•°æ®
                readable.push(`data: ${data}\n\n`);
              }
            } catch (e) {
              console.warn('è§£ææµå¼æ•°æ®å¤±è´¥:', e);
            }
          }
        }
      });

      response.on('end', () => {
        console.log('\x1b[32m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] å“åº”æµç»“æŸ\x1b[0m');
        if (!readable.destroyed) {
          readable.push(null);
        }
      });

      response.on('error', (error: any) => {
        console.error('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] å“åº”æµé”™è¯¯:\x1b[0m', error);
        readable.destroy(error);
      });

      return readable;

    } catch (error: any) {
      console.error('\x1b[31m[AIè°ƒç”¨-åŸç”ŸHTTPæµå¼] æµå¼è¯·æ±‚å¤±è´¥:\x1b[0m', error.message);
      throw new Error('æµå¼AIè°ƒç”¨å¤±è´¥: ' + error.message);
    }
  }

  /**
   * ä¿å­˜æµå¼è¾“å‡ºçš„å®Œæ•´æ¶ˆæ¯åˆ°æ•°æ®åº“
   */
  private async saveStreamedMessage(conversationId: string, userId: number, content: string, metadata: any = {}) {
    try {
      // åŠ¨æ€å¯¼å…¥æ¨¡å‹ä»¥é¿å…å¾ªç¯ä¾èµ–
      const { AIMessage } = await import('../../../models');
      const { AIConversation } = await import('../../../models/ai-conversation.model');
      const { MessageRole, MessageType, MessageStatus } = await import('../../../models/ai-message.model');

      // å¯¼å…¥å…­ç»´è®°å¿†ç³»ç»Ÿ
      const { getMemorySystem } = await import('../../memory/six-dimension-memory.service');

      console.log('ä¿å­˜æµå¼æ¶ˆæ¯:', { conversationId, userId, contentLength: content.length });

      // ğŸ§  ä»…ä½¿ç”¨å…­ç»´è®°å¿†ç³»ç»Ÿ - è®°å½•AIå›å¤åˆ°æƒ…èŠ‚è®°å¿†
      try {
        const memorySystem = getMemorySystem();

        // ç”Ÿæˆå”¯ä¸€æ¶ˆæ¯IDï¼ˆç”¨äºå…­ç»´è®°å¿†ç³»ç»Ÿï¼‰
        const messageId = `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;

        await memorySystem.recordConversation(
          'assistant',
          content,
          {
            userId: userId.toString(),
            conversationId,
            messageId,
            role: 'assistant',
            timestamp: new Date(),
            metadata
          }
        );
        console.log('âœ… å…­ç»´è®°å¿†ç³»ç»Ÿå·²è®°å½•AIå›å¤', {
          userId,
          conversationId,
          messageId,
          contentLength: content.length
        });
      } catch (memoryError) {
        console.error('âŒ å…­ç»´è®°å¿†ç³»ç»Ÿè®°å½•å¤±è´¥:', memoryError instanceof Error ? memoryError.message : String(memoryError));
        // å¦‚æœå…­ç»´è®°å¿†ç³»ç»Ÿå¤±è´¥ï¼ŒæŠ›å‡ºé”™è¯¯è€Œä¸æ˜¯å›é€€åˆ°ä¼ ç»Ÿå­˜å‚¨
        throw new Error(`å…­ç»´è®°å¿†ç³»ç»Ÿè®°å½•å¤±è´¥: ${memoryError instanceof Error ? memoryError.message : String(memoryError)}`);
      }

      // æ›´æ–°ä¼šè¯çš„æ¶ˆæ¯è®¡æ•°
      await AIConversation.increment('messageCount', {
        where: { id: conversationId }
      });

      console.log('æµå¼æ¶ˆæ¯å·²é€šè¿‡å…­ç»´è®°å¿†ç³»ç»Ÿä¿å­˜æˆåŠŸ');

    } catch (error) {
      console.error('ä¿å­˜æµå¼æ¶ˆæ¯å¤±è´¥:', error);
    }
  }

  /**
   * Get the default AI model configuration from database
   * @returns Default AI model configuration
   */
  private async getDefaultModelConfig(): Promise<AIModelConfig | null> {
    try {
      const defaultModel = await AIModelConfig.findOne({
        where: {
          isDefault: true,
          status: ModelStatus.ACTIVE
        }
      });
      return defaultModel;
    } catch (error) {
      console.error('Failed to get default model config:', error);
      return null;
    }
  }

  /**
   * ğŸš€ è·å–å¿«é€Ÿæ¨ç†æ¨¡å‹é…ç½® - ä¸“ä¸ºCRUDå·¥å…·ä¼˜åŒ–
   * @returns å¿«é€Ÿæ¨ç†æ¨¡å‹é…ç½®
   */
  private async getFastModelConfig(): Promise<AIModelConfig | null> {
    try {
      // ä¼˜å…ˆæŸ¥æ‰¾Flashæ¨¡å‹
      const flashModel = await AIModelConfig.findOne({
        where: {
          name: 'doubao-seed-1-6-flash-250715',
          status: ModelStatus.ACTIVE
        }
      });

      if (flashModel) {
        console.log('ğŸš€ [AIBridge] ä½¿ç”¨Flashå¿«é€Ÿæ¨ç†æ¨¡å‹');
        return flashModel;
      }

      // å¦‚æœFlashæ¨¡å‹ä¸å¯ç”¨ï¼Œå›é€€åˆ°é»˜è®¤æ¨¡å‹
      console.log('âš ï¸ [AIBridge] Flashæ¨¡å‹ä¸å¯ç”¨ï¼Œå›é€€åˆ°é»˜è®¤æ¨¡å‹');
      return await this.getDefaultModelConfig();
    } catch (error) {
      console.error('Failed to get fast model config:', error);
      return await this.getDefaultModelConfig();
    }
  }

  /**
   * ğŸ§  è·å–æ·±åº¦æ€è€ƒæ¨¡å‹é…ç½® - ä¸“ä¸ºå¤æ‚æ¨ç†ä¼˜åŒ–
   * @returns æ·±åº¦æ€è€ƒæ¨¡å‹é…ç½®
   */
  private async getThinkingModelConfig(): Promise<AIModelConfig | null> {
    try {
      // ä¼˜å…ˆæŸ¥æ‰¾Thinkingæ¨¡å‹
      const thinkingModel = await AIModelConfig.findOne({
        where: {
          name: 'doubao-seed-1-6-thinking-250615',
          status: ModelStatus.ACTIVE
        }
      });

      if (thinkingModel) {
        console.log('ğŸ§  [AIBridge] ä½¿ç”¨Thinkingæ·±åº¦æ€è€ƒæ¨¡å‹');
        return thinkingModel;
      }

      // å¦‚æœThinkingæ¨¡å‹ä¸å¯ç”¨ï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»–thinkingæ¨¡å‹
      const alternativeThinkingModel = await AIModelConfig.findOne({
        where: {
          name: {
            [Op.like]: '%thinking%'
          },
          status: ModelStatus.ACTIVE
        }
      });

      if (alternativeThinkingModel) {
        console.log('ğŸ§  [AIBridge] ä½¿ç”¨å¤‡é€‰Thinkingæ¨¡å‹:', alternativeThinkingModel.name);
        return alternativeThinkingModel;
      }

      // å¦‚æœæ²¡æœ‰thinkingæ¨¡å‹ï¼Œå›é€€åˆ°é»˜è®¤æ¨¡å‹
      console.log('âš ï¸ [AIBridge] Thinkingæ¨¡å‹ä¸å¯ç”¨ï¼Œå›é€€åˆ°é»˜è®¤æ¨¡å‹');
      return await this.getDefaultModelConfig();
    } catch (error) {
      console.error('Failed to get thinking model config:', error);
      return await this.getDefaultModelConfig();
    }
  }

  /**
   * ğŸ¯ ä¸“ä¸ºCRUDå·¥å…·ä¼˜åŒ–çš„å¿«é€ŸèŠå¤©å®Œæˆ
   * @param params - èŠå¤©å®Œæˆå‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
   * @returns èŠå¤©å®Œæˆå“åº”
   */
  async generateFastChatCompletion(
    params: AiBridgeChatCompletionParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeChatCompletionResponse> {
    try {
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
      console.log('ğŸš€ [AIBridge] å¼€å§‹å¿«é€Ÿæ¨ç†');
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

      // è·å–å¿«é€Ÿæ¨¡å‹é…ç½®
      const fastModelConfig = await this.getFastModelConfig();

      if (!fastModelConfig) {
        throw new Error('No fast model configuration available');
      }

      console.log('ğŸ“‹ [AIBridge] å¿«é€Ÿæ¨¡å‹é…ç½®:', fastModelConfig.displayName);
      console.log('ğŸ“ [AIBridge] æ¶ˆæ¯æ•°é‡:', params.messages?.length);
      console.log('ğŸ”§ [AIBridge] å·¥å…·æ•°é‡:', params.tools?.length || 0);

      // ä¼˜åŒ–å‚æ•°ç”¨äºå¿«é€Ÿæ¨ç†
      const optimizedParams: AiBridgeChatCompletionParams = {
        ...params,
        model: fastModelConfig.name,
        temperature: 0.1,  // ä½æ¸©åº¦ç¡®ä¿ç¨³å®šè¾“å‡º
        max_tokens: 1024,  // é™åˆ¶tokenæ•°æé«˜é€Ÿåº¦
        stream: false      // ä¸ä½¿ç”¨æµå¼è¾“å‡º
      };

      // ä½¿ç”¨å¿«é€Ÿæ¨¡å‹é…ç½®
      const fastConfig = customConfig || {
        endpointUrl: fastModelConfig.endpointUrl,
        apiKey: fastModelConfig.apiKey
      };

      console.log(`ğŸš€ [AIBridge] ä½¿ç”¨å¿«é€Ÿæ¨ç†æ¨¡å‹: ${fastModelConfig.displayName}`);
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

      return await this.generateChatCompletion(optimizedParams, fastConfig);
    } catch (error) {
      console.error('âŒ [AIBridge] å¿«é€ŸèŠå¤©å®Œæˆå¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * ğŸ§  ä¸“ä¸ºå¤æ‚æ¨ç†ä¼˜åŒ–çš„æ·±åº¦æ€è€ƒèŠå¤©å®Œæˆ
   * ä½¿ç”¨ä¸“é—¨çš„Thinkingæ¨¡å‹ï¼ˆdoubao-seed-1-6-thinking-250615ï¼‰
   * @param params - èŠå¤©å®Œæˆå‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
   * @param userId - ç”¨æˆ·IDï¼ˆç”¨äºä½¿ç”¨é‡ç»Ÿè®¡ï¼‰
   * @returns èŠå¤©å®Œæˆå“åº”
   */
  async generateThinkingChatCompletion(
    params: AiBridgeChatCompletionParams,
    customConfig?: { endpointUrl: string; apiKey: string },
    userId?: number
  ): Promise<AiBridgeChatCompletionResponse> {
    try {
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');
      console.log('ğŸ§  [AIBridge] å¼€å§‹æ·±åº¦æ€è€ƒæ¨ç†');
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

      // è·å–æ·±åº¦æ€è€ƒæ¨¡å‹é…ç½®
      const thinkingModelConfig = await this.getThinkingModelConfig();

      if (!thinkingModelConfig) {
        throw new Error('No thinking model configuration available');
      }

      console.log('ğŸ“‹ [AIBridge] æ·±åº¦æ€è€ƒæ¨¡å‹é…ç½®:', thinkingModelConfig.displayName);
      console.log('ğŸ“ [AIBridge] æ¶ˆæ¯æ•°é‡:', params.messages?.length);
      console.log('ğŸ”§ [AIBridge] å·¥å…·æ•°é‡:', params.tools?.length || 0);
      console.log('ğŸ‘¤ [AIBridge] ç”¨æˆ·ID:', userId);

      // ä¼˜åŒ–å‚æ•°ç”¨äºæ·±åº¦æ€è€ƒ
      const optimizedParams: AiBridgeChatCompletionParams = {
        ...params,
        model: thinkingModelConfig.name,
        temperature: params.temperature || 0.7,  // ä¸­ç­‰æ¸©åº¦å¹³è¡¡åˆ›é€ æ€§å’Œå‡†ç¡®æ€§
        max_tokens: params.max_tokens || 4000,   // æ›´å¤štokenæ”¯æŒå¤æ‚æ¨ç†
        stream: params.stream !== undefined ? params.stream : false  // ä¿ç•™ç”¨æˆ·æŒ‡å®šçš„streamè®¾ç½®
      };

      // ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹é…ç½®
      const thinkingConfig = customConfig || {
        endpointUrl: thinkingModelConfig.endpointUrl,
        apiKey: thinkingModelConfig.apiKey
      };

      console.log(`ğŸ§  [AIBridge] ä½¿ç”¨æ·±åº¦æ€è€ƒæ¨¡å‹: ${thinkingModelConfig.displayName}`);
      console.log(`ğŸ§  [AIBridge] å‚æ•°é…ç½®: temperature=${optimizedParams.temperature}, max_tokens=${optimizedParams.max_tokens}, stream=${optimizedParams.stream}`);
      console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”');

      return await this.generateChatCompletion(optimizedParams, thinkingConfig, userId);
    } catch (error) {
      console.error('âŒ [AIBridge] æ·±åº¦æ€è€ƒèŠå¤©å®Œæˆå¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * ğŸ’¡ Flashæ¨¡å‹çš„æ€è€ƒæ¨¡å¼èŠå¤©å®Œæˆ
   * ä½¿ç”¨Flashæ¨¡å‹ + thinkå‚æ•° + ä¸­ç­‰æ¸©åº¦
   * é€‚åˆéœ€è¦Flashé€Ÿåº¦ä½†åˆéœ€è¦ä¸€å®šæ€è€ƒæ·±åº¦çš„åœºæ™¯
   * @param params - èŠå¤©å®Œæˆå‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®ï¼ˆå¯é€‰ï¼‰
   * @param userId - ç”¨æˆ·IDï¼ˆç”¨äºä½¿ç”¨é‡ç»Ÿè®¡ï¼‰
   * @returns èŠå¤©å®Œæˆå“åº”
   */
  async generateFlashWithThink(
    params: AiBridgeChatCompletionParams,
    customConfig?: { endpointUrl: string; apiKey: string },
    userId?: number
  ): Promise<AiBridgeChatCompletionResponse> {
    try {
      // è·å–Flashæ¨¡å‹é…ç½®
      const flashModelConfig = await this.getFastModelConfig();

      if (!flashModelConfig) {
        throw new Error('No flash model configuration available');
      }

      // ä¼˜åŒ–å‚æ•°ç”¨äºFlashæ€è€ƒæ¨¡å¼
      const optimizedParams: AiBridgeChatCompletionParams = {
        ...params,
        model: flashModelConfig.name,
        temperature: params.temperature || 0.7,  // ä¸­ç­‰æ¸©åº¦æ”¯æŒæ€è€ƒ
        max_tokens: params.max_tokens || 2000,   // é€‚ä¸­çš„tokenæ•°
        think: true,  // å¯ç”¨æ€è€ƒæ¨¡å¼
        stream: params.stream !== undefined ? params.stream : false
      };

      // ä½¿ç”¨Flashæ¨¡å‹é…ç½®
      const flashConfig = customConfig || {
        endpointUrl: flashModelConfig.endpointUrl,
        apiKey: flashModelConfig.apiKey
      };

      console.log(`ğŸ’¡ [AIBridge] ä½¿ç”¨Flashæ€è€ƒæ¨¡å¼: ${flashModelConfig.displayName}`);
      console.log(`ğŸ’¡ [AIBridge] å‚æ•°é…ç½®: temperature=${optimizedParams.temperature}, max_tokens=${optimizedParams.max_tokens}, think=true`);

      return await this.generateChatCompletion(optimizedParams, flashConfig, userId);
    } catch (error) {
      console.error('âŒ [AIBridge] Flashæ€è€ƒæ¨¡å¼èŠå¤©å®Œæˆå¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * High-level analyze method for AI enrollment services
   * @param prompt - The analysis prompt
   * @param options - Analysis options and context
   * @returns Structured analysis result
   */
  public async analyze(prompt: string, options: {
    type: string;
    context: string;
    requireStructured?: boolean;
  }): Promise<any> {
    try {
      // è·å–æ•°æ®åº“ä¸­çš„é»˜è®¤æ¨¡å‹é…ç½®
      const modelConfig = await this.getDefaultModelConfig();
      
      if (!modelConfig) {
        throw new Error('No active AI model configuration found');
      }

      const messages: AiBridgeMessage[] = [
        {
          role: 'system' as AiBridgeMessageRole,
          content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å¹¼å„¿å›­æ‹›ç”Ÿåˆ†æä¸“å®¶ï¼Œå…·æœ‰ä¸°å¯Œçš„æ•°æ®åˆ†æå’Œå¸‚åœºé¢„æµ‹ç»éªŒã€‚
è¯·æ ¹æ®ç”¨æˆ·çš„è¦æ±‚è¿›è¡Œä¸“ä¸šåˆ†æï¼Œå¹¶æä¾›å‡†ç¡®ã€å®ç”¨çš„å»ºè®®ã€‚
åˆ†æç±»å‹: ${options.type}
ä¸Šä¸‹æ–‡: ${options.context}
${options.requireStructured ? 'è¯·ä»¥ç»“æ„åŒ–çš„JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚' : ''}`
        },
        {
          role: 'user' as AiBridgeMessageRole,
          content: prompt
        }
      ];

      // ä½¿ç”¨æ•°æ®åº“ä¸­çš„æ¨¡å‹é…ç½®
      const response = await this.generateChatCompletion({
        model: modelConfig.name,
        messages,
        temperature: modelConfig.modelParameters?.temperature || 0.7,
        max_tokens: modelConfig.modelParameters?.maxTokens || 2000
      }, {
        endpointUrl: modelConfig.endpointUrl,
        apiKey: modelConfig.apiKey
      });

      let result: any = response.choices[0]?.message?.content || '';
      
      // å¦‚æœéœ€è¦ç»“æ„åŒ–æ•°æ®ï¼Œå°è¯•è§£æJSON
      if (options.requireStructured) {
        try {
          // æå–JSONå†…å®¹
          const jsonMatch = result.match(/\{[\s\S]*\}/);
          if (jsonMatch) {
            result = JSON.parse(jsonMatch[0]);
          } else {
            // å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONï¼Œè¿”å›åŒ…è£…çš„ç»“æœ
            result = { content: result, type: options.type };
          }
        } catch (parseError) {
          console.warn('Failed to parse structured response, returning raw content');
          result = { content: result, type: options.type };
        }
      }

      return result;
    } catch (error) {
      console.error('AI analysis failed:', error);
      throw new Error(`AI ${options.type} åˆ†æå¤±è´¥`);
    }
  }

  // ==================== å¤šæ¨¡æ€æ–¹æ³• ====================

  /**
   * å›¾ç‰‡ç”Ÿæˆ
   * @param params - å›¾ç‰‡ç”Ÿæˆå‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®
   * @returns å›¾ç‰‡ç”Ÿæˆç»“æœ
   */
  public async generateImage(
    params: AiBridgeImageGenerationParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeImageGenerationResponse> {
    try {
      let httpClient = this.defaultHttpClient;
      let endpoint = '/images/generations';

      // ğŸ”§ ä¼˜åŒ–ï¼šå¦‚æœæ²¡æœ‰æä¾›customConfigï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®
      if (!customConfig && params.model) {
        console.log(`ğŸ” [å›¾ç‰‡ç”Ÿæˆ] æœªæä¾›è‡ªå®šä¹‰é…ç½®ï¼Œå°è¯•ä»æ•°æ®åº“è¯»å–æ¨¡å‹é…ç½®: ${params.model}`);

        try {
          const AIModelConfigModule = await import('../../../models/ai-model-config.model');
          const AIModelConfig = AIModelConfigModule.default;
          const modelConfig = await AIModelConfig.findOne({
            where: { name: params.model, status: 'active' }
          });

          if (modelConfig) {
            customConfig = {
              endpointUrl: modelConfig.endpointUrl,
              apiKey: modelConfig.apiKey || ''
            };
            console.log(`âœ… [å›¾ç‰‡ç”Ÿæˆ] ä»æ•°æ®åº“åŠ è½½æ¨¡å‹é…ç½®æˆåŠŸ: ${modelConfig.displayName}`);
          }
        } catch (dbError) {
          console.error(`âŒ [å›¾ç‰‡ç”Ÿæˆ] ä»æ•°æ®åº“è¯»å–é…ç½®å¤±è´¥:`, dbError);
        }
      }

      if (customConfig) {
        httpClient = this.createCustomHttpClient(customConfig.endpointUrl, customConfig.apiKey);
        endpoint = '/images/generations';
        console.log('ğŸ¨ [å›¾ç‰‡ç”Ÿæˆ] ä½¿ç”¨è‡ªå®šä¹‰é…ç½®');
      }

      console.log('ğŸ¨ [å›¾ç‰‡ç”Ÿæˆ] è¯·æ±‚å‚æ•°:', JSON.stringify(params, null, 2));

      const networkConfig = AIConfigService.getNetworkConfig();

      for (let attempt = 1; attempt <= networkConfig.maxRetries; attempt++) {
        try {
          const response = await httpClient.post<AiBridgeImageGenerationResponse>(endpoint, params);
          console.log(`ğŸ¨ [å›¾ç‰‡ç”Ÿæˆ] ç¬¬ ${attempt} æ¬¡è°ƒç”¨æˆåŠŸ`);
          return response.data;
        } catch (retryError) {
          if (attempt < networkConfig.maxRetries && axios.isAxiosError(retryError) && retryError.response?.status === 503) {
            console.log(`ğŸ¨ [å›¾ç‰‡ç”Ÿæˆ] ç¬¬ ${attempt} æ¬¡è°ƒç”¨å¤±è´¥ï¼Œå‡†å¤‡é‡è¯•`);
            await new Promise(resolve => setTimeout(resolve, networkConfig.retryDelay * attempt));
            continue;
          }
          throw retryError;
        }
      }
    } catch (error) {
      console.error('ğŸ¨ [å›¾ç‰‡ç”Ÿæˆ] è°ƒç”¨å¤±è´¥:', error);
      throw new Error('å›¾ç‰‡ç”Ÿæˆå¤±è´¥');
    }
  }

  /**
   * è¯­éŸ³è½¬æ–‡æœ¬
   * @param params - è¯­éŸ³è½¬æ–‡æœ¬å‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®
   * @returns è¯­éŸ³è½¬æ–‡æœ¬ç»“æœ
   */
  public async speechToText(
    params: AiBridgeSpeechToTextParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeSpeechToTextResponse> {
    try {
      let httpClient = this.defaultHttpClient;
      let endpoint = '/audio/transcriptions';

      if (customConfig) {
        httpClient = this.createCustomHttpClient(customConfig.endpointUrl, customConfig.apiKey, 'multipart/form-data');
        endpoint = '/audio/transcriptions';
        console.log('ğŸ¤ [è¯­éŸ³è½¬æ–‡æœ¬] ä½¿ç”¨è‡ªå®šä¹‰é…ç½®');
      }

      // æ„å»ºFormData
      const formData = new FormData();
      formData.append('file', params.file, params.filename);
      formData.append('model', params.model);

      if (params.language) formData.append('language', params.language);
      if (params.prompt) formData.append('prompt', params.prompt);
      if (params.response_format) formData.append('response_format', params.response_format);
      if (params.temperature) formData.append('temperature', params.temperature.toString());

      console.log('ğŸ¤ [è¯­éŸ³è½¬æ–‡æœ¬] å¼€å§‹å¤„ç†');

      const response = await httpClient.post<AiBridgeSpeechToTextResponse>(endpoint, formData, {
        headers: {
          ...formData.getHeaders(),
          'Authorization': httpClient.defaults.headers['Authorization']
        }
      });

      console.log('ğŸ¤ [è¯­éŸ³è½¬æ–‡æœ¬] å¤„ç†æˆåŠŸ');
      return response.data;
    } catch (error) {
      console.error('ğŸ¤ [è¯­éŸ³è½¬æ–‡æœ¬] è°ƒç”¨å¤±è´¥:', error);
      throw new Error('è¯­éŸ³è½¬æ–‡æœ¬å¤±è´¥');
    }
  }

  /**
   * æ–‡æœ¬è½¬è¯­éŸ³
   * @param params - æ–‡æœ¬è½¬è¯­éŸ³å‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®
   * @returns æ–‡æœ¬è½¬è¯­éŸ³ç»“æœ
   */
  public async textToSpeech(
    params: AiBridgeTextToSpeechParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeTextToSpeechResponse> {
    try {
      console.log('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] å¼€å§‹å¤„ç†:', JSON.stringify(params, null, 2));

      // æ£€æŸ¥æ˜¯å¦ä½¿ç”¨V3 WebSocketç«¯ç‚¹
      const isV3WebSocket = customConfig?.endpointUrl?.includes('wss://') ||
                           customConfig?.endpointUrl?.includes('/v3/tts');

      if (isV3WebSocket) {
        // ä½¿ç”¨V3 WebSocketåŒå‘æµå¼æœåŠ¡
        console.log('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] ä½¿ç”¨V3 WebSocketåŒå‘æµå¼æœåŠ¡');

        // åŠ¨æ€å¯¼å…¥V3åŒå‘æµå¼æœåŠ¡
        const { VolcengineTTSV3BidirectionService } = await import('../../volcengine/tts-v3-bidirection.service');

        // ä»customConfigä¸­æå–é…ç½®
        // å‡è®¾apiKeyæ˜¯appKeyï¼Œæˆ–è€…ä»model_parametersä¸­è·å–
        let appKey = customConfig!.apiKey;
        let accessKey = '';

        // å¦‚æœendpointåŒ…å«bidirectionï¼Œå°è¯•ä»æ•°æ®åº“åŠ è½½å®Œæ•´é…ç½®
        try {
          const modelConfig = await AIModelConfig.findOne({
            where: {
              endpointUrl: customConfig!.endpointUrl,
              status: ModelStatus.ACTIVE
            }
          });

          if (modelConfig && modelConfig.modelParameters) {
            const params = typeof modelConfig.modelParameters === 'string'
              ? JSON.parse(modelConfig.modelParameters)
              : modelConfig.modelParameters;
            appKey = params.appKey || appKey;
            accessKey = params.accessKey || '';
          }
        } catch (e) {
          console.warn('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] æ— æ³•ä»æ•°æ®åº“åŠ è½½é…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼');
        }

        // åˆ›å»ºV3åŒå‘æµå¼æœåŠ¡å®ä¾‹
        const ttsV3Service = new VolcengineTTSV3BidirectionService({
          appKey: appKey,
          accessKey: accessKey,
          wsUrl: customConfig!.endpointUrl
        });

        // è°ƒç”¨V3æœåŠ¡
        const result = await ttsV3Service.textToSpeech({
          text: params.input,
          speaker: params.voice || 'zh_female_cancan_mars_bigtts',
          format: 'mp3',
          speedRatio: params.speed || 1.0
        });

        console.log('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] V3åŒå‘æµå¼å¤„ç†æˆåŠŸ');

        return {
          success: true,
          audioData: result.audioBuffer,
          contentType: 'audio/mpeg'
        };
      } else {
        // ä½¿ç”¨ä¼ ç»ŸHTTPç«¯ç‚¹
        let httpClient = this.defaultHttpClient;
        let endpoint = '/audio/speech';

        if (customConfig) {
          httpClient = this.createCustomHttpClient(customConfig.endpointUrl, customConfig.apiKey);
          endpoint = '/audio/speech';
          console.log('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] ä½¿ç”¨è‡ªå®šä¹‰HTTPé…ç½®');
        }

        const response = await httpClient.post(endpoint, params, {
          responseType: 'arraybuffer'
        });

        console.log('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] HTTPå¤„ç†æˆåŠŸ');

        return {
          success: true,
          audioData: Buffer.from(response.data),
          contentType: response.headers['content-type'] || 'audio/mpeg'
        };
      }
    } catch (error: any) {
      console.error('ğŸ”Š [æ–‡æœ¬è½¬è¯­éŸ³] è°ƒç”¨å¤±è´¥:', error.message);
      throw new Error(`æ–‡æœ¬è½¬è¯­éŸ³å¤±è´¥: ${error.message}`);
    }
  }

  /**
   * è§†é¢‘ç”Ÿæˆï¼ˆå§”æ‰˜ç»™ä¸“ä¸šçš„ video.serviceï¼‰
   * @param params - è§†é¢‘ç”Ÿæˆå‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®
   * @returns è§†é¢‘ç”Ÿæˆç»“æœ
   */
  public async generateVideo(
    params: AiBridgeVideoGenerationParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeVideoGenerationResponse> {
    try {
      console.log('ğŸ¬ [AI-Bridge] è§†é¢‘ç”Ÿæˆè¯·æ±‚ï¼Œå§”æ‰˜ç»™ VideoService');
      console.log('ğŸ¬ [AI-Bridge] å‚æ•°:', JSON.stringify(params, null, 2));

      // è§†é¢‘æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ
      console.log('âš ï¸ [AI-Bridge] è§†é¢‘æœåŠ¡æš‚æœªå®ç°ï¼Œè¿”å›æ¨¡æ‹Ÿç»“æœ');
      const result = {
        success: false,
        message: 'è§†é¢‘æœåŠ¡åŠŸèƒ½æš‚æœªå®ç°',
        data: null
      };

      console.log('ğŸ¬ [AI-Bridge] è§†é¢‘ç”ŸæˆæˆåŠŸ');
      return result;

    } catch (error) {
      console.error('ğŸ¬ [AI-Bridge] è§†é¢‘ç”Ÿæˆå¤±è´¥:', error);
      throw new Error('è§†é¢‘ç”Ÿæˆå¤±è´¥');
    }
  }

  /**
   * VODè§†é¢‘ä¸Šä¼ ï¼ˆå§”æ‰˜ç»™ vod.serviceï¼‰
   * @param params - ä¸Šä¼ å‚æ•°
   * @returns ä¸Šä¼ ç»“æœ
   */
  public async uploadVideoToVOD(
    params: AiBridgeVODUploadParams
  ): Promise<AiBridgeVODUploadResponse> {
    try {
      console.log('ğŸ“¤ [AI-Bridge] VODè§†é¢‘ä¸Šä¼ è¯·æ±‚');

      // åŠ¨æ€å¯¼å…¥ vod.service
      const { vodService } = await import('../../volcengine/vod.service');

      // å§”æ‰˜ç»™VODæœåŠ¡å¤„ç†
      const result = await vodService.uploadVideo(params.videoBuffer, params.filename);

      console.log('ğŸ“¤ [AI-Bridge] VODè§†é¢‘ä¸Šä¼ æˆåŠŸ');
      return result;

    } catch (error) {
      console.error('ğŸ“¤ [AI-Bridge] VODè§†é¢‘ä¸Šä¼ å¤±è´¥:', error);
      throw new Error('VODè§†é¢‘ä¸Šä¼ å¤±è´¥');
    }
  }

  /**
   * VODè§†é¢‘åˆå¹¶ï¼ˆå§”æ‰˜ç»™ vod.serviceï¼‰
   * @param params - åˆå¹¶å‚æ•°
   * @returns åˆå¹¶ç»“æœ
   */
  public async mergeVideosVOD(
    params: AiBridgeVODMergeParams
  ): Promise<AiBridgeVODMergeResponse> {
    try {
      console.log('âœ‚ï¸ [AI-Bridge] VODè§†é¢‘åˆå¹¶è¯·æ±‚');
      console.log(`âœ‚ï¸ [AI-Bridge] åˆå¹¶ ${params.videoUrls.length} ä¸ªè§†é¢‘ç‰‡æ®µ`);

      // åŠ¨æ€å¯¼å…¥ vod.service
      const { vodService } = await import('../../volcengine/vod.service');

      // å§”æ‰˜ç»™VODæœåŠ¡å¤„ç†
      const result = await vodService.mergeVideos(params.videoUrls, params.outputFilename);

      console.log('âœ‚ï¸ [AI-Bridge] VODè§†é¢‘åˆå¹¶æˆåŠŸ');
      return result;

    } catch (error) {
      console.error('âœ‚ï¸ [AI-Bridge] VODè§†é¢‘åˆå¹¶å¤±è´¥:', error);
      throw new Error('VODè§†é¢‘åˆå¹¶å¤±è´¥');
    }
  }

  /**
   * VODæ·»åŠ éŸ³é¢‘ï¼ˆå§”æ‰˜ç»™ vod.serviceï¼‰
   * @param params - æ·»åŠ éŸ³é¢‘å‚æ•°
   * @returns æ·»åŠ éŸ³é¢‘ç»“æœ
   */
  public async addAudioToVideoVOD(
    params: AiBridgeVODAddAudioParams
  ): Promise<AiBridgeVODAddAudioResponse> {
    try {
      console.log('ğŸ¤ [AI-Bridge] VODæ·»åŠ éŸ³é¢‘è¯·æ±‚');

      // åŠ¨æ€å¯¼å…¥ vod.service
      const { vodService } = await import('../../volcengine/vod.service');

      // å§”æ‰˜ç»™VODæœåŠ¡å¤„ç†
      const result = await vodService.addAudioToVideo(
        params.videoUrl,
        params.audioUrl,
        params.outputFilename
      );

      console.log('ğŸ¤ [AI-Bridge] VODæ·»åŠ éŸ³é¢‘æˆåŠŸ');
      return result;

    } catch (error) {
      console.error('ğŸ¤ [AI-Bridge] VODæ·»åŠ éŸ³é¢‘å¤±è´¥:', error);
      throw new Error('VODæ·»åŠ éŸ³é¢‘å¤±è´¥');
    }
  }

  /**
   * VODè§†é¢‘è½¬ç ï¼ˆå§”æ‰˜ç»™ vod.serviceï¼‰
   * @param params - è½¬ç å‚æ•°
   * @returns è½¬ç ç»“æœ
   */
  public async transcodeVideoVOD(
    params: AiBridgeVODTranscodeParams
  ): Promise<AiBridgeVODTranscodeResponse> {
    try {
      console.log('ğŸ”„ [AI-Bridge] VODè§†é¢‘è½¬ç è¯·æ±‚');

      // åŠ¨æ€å¯¼å…¥ vod.service
      const { vodService } = await import('../../volcengine/vod.service');

      // å§”æ‰˜ç»™VODæœåŠ¡å¤„ç†
      const result = await vodService.transcodeVideo(
        params.videoUrl,
        params.format || 'mp4',
        (params.quality || 'high') as 'low' | 'medium' | 'high'
      );

      console.log('ğŸ”„ [AI-Bridge] VODè§†é¢‘è½¬ç æˆåŠŸ');
      return result;

    } catch (error) {
      console.error('ğŸ”„ [AI-Bridge] VODè§†é¢‘è½¬ç å¤±è´¥:', error);
      throw new Error('VODè§†é¢‘è½¬ç å¤±è´¥');
    }
  }

  /**
   * VODä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ï¼ˆå§”æ‰˜ç»™ vod.serviceï¼‰
   * @param params - æŸ¥è¯¢å‚æ•°
   * @returns ä»»åŠ¡çŠ¶æ€
   */
  public async getVODTaskStatus(
    params: AiBridgeVODTaskStatusParams
  ): Promise<AiBridgeVODTaskStatusResponse> {
    try {
      console.log('ğŸ“Š [AI-Bridge] VODä»»åŠ¡çŠ¶æ€æŸ¥è¯¢');

      // åŠ¨æ€å¯¼å…¥ vod.service
      const { vodService } = await import('../../volcengine/vod.service');

      // å§”æ‰˜ç»™VODæœåŠ¡å¤„ç†
      const result = await vodService.getTaskStatus(params.taskId);

      console.log('ğŸ“Š [AI-Bridge] VODä»»åŠ¡çŠ¶æ€æŸ¥è¯¢æˆåŠŸ');
      return result;

    } catch (error) {
      console.error('ğŸ“Š [AI-Bridge] VODä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å¤±è´¥:', error);
      throw new Error('VODä»»åŠ¡çŠ¶æ€æŸ¥è¯¢å¤±è´¥');
    }
  }

  /**
   * æ–‡æ¡£å¤„ç†
   * @param params - æ–‡æ¡£å¤„ç†å‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®
   * @returns æ–‡æ¡£å¤„ç†ç»“æœ
   */
  public async processDocument(
    params: AiBridgeDocumentParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeDocumentResponse> {
    try {
      let httpClient = this.defaultHttpClient;
      let endpoint = '/documents/process';

      if (customConfig) {
        httpClient = this.createCustomHttpClient(customConfig.endpointUrl, customConfig.apiKey, 'multipart/form-data');
        endpoint = '/documents/process';
        console.log('ğŸ“„ [æ–‡æ¡£å¤„ç†] ä½¿ç”¨è‡ªå®šä¹‰é…ç½®');
      }

      // æ„å»ºFormData
      const formData = new FormData();
      formData.append('file', params.document, params.filename);
      formData.append('model', params.model);
      formData.append('task', params.task);

      if (params.language) formData.append('language', params.language);
      if (params.format) formData.append('format', params.format);

      console.log('ğŸ“„ [æ–‡æ¡£å¤„ç†] å¼€å§‹å¤„ç†');

      const response = await httpClient.post<AiBridgeDocumentResponse>(endpoint, formData, {
        headers: {
          ...formData.getHeaders(),
          'Authorization': httpClient.defaults.headers['Authorization']
        }
      });

      console.log('ğŸ“„ [æ–‡æ¡£å¤„ç†] å¤„ç†æˆåŠŸ');
      return response.data;
    } catch (error) {
      console.error('ğŸ“„ [æ–‡æ¡£å¤„ç†] è°ƒç”¨å¤±è´¥:', error);
      throw new Error('æ–‡æ¡£å¤„ç†å¤±è´¥');
    }
  }

  /**
   * ç½‘ç»œæœç´¢
   * @param params - æœç´¢å‚æ•°
   * @param customConfig - è‡ªå®šä¹‰é…ç½®ï¼ˆåŒ…å«endpointå’ŒapiKeyï¼‰
   * @returns æœç´¢ç»“æœ
   */
  public async search(
    params: AiBridgeSearchParams,
    customConfig?: { endpointUrl: string; apiKey: string }
  ): Promise<AiBridgeSearchResponse> {
    const startTime = Date.now();

    try {
      console.log('ğŸ” [AI-Bridge] å¼€å§‹ç½‘ç»œæœç´¢:', params.query);

      // è·å–æœç´¢æ¨¡å‹é…ç½®ä»¥ç¡®å®šmax_tokens
      const modelConfigService = (await import('../ai-model-config.service')).default;
      const searchModel = await modelConfigService.getDefaultModel('search');
      const maxTokens = searchModel?.maxTokens || 2048;

      // æ„å»ºæœç´¢è¯·æ±‚ä½“ï¼ˆç«å±±å¼•æ“èåˆæœç´¢æ ¼å¼ï¼‰
      const requestBody = {
        Query: params.query,
        SearchType: params.searchType || 'web_summary',
        Count: params.maxResults || 5,
        NeedSummary: params.enableAISummary !== false,
        Language: params.language || 'zh-CN',
        MaxSummaryLength: maxTokens // ğŸ”§ æ§åˆ¶AIæ€»ç»“çš„æœ€å¤§é•¿åº¦
      };

      console.log('ğŸ” [AI-Bridge] æœç´¢å‚æ•°:', JSON.stringify(requestBody, null, 2));

      // ä½¿ç”¨è‡ªå®šä¹‰é…ç½®æˆ–é»˜è®¤é…ç½®
      const endpoint = customConfig?.endpointUrl || process.env.VOLCANO_SEARCH_ENDPOINT || 'https://open.feedcoopapi.com/search_api/web_search';
      const apiKey = customConfig?.apiKey || process.env.VOLCANO_API_KEY || '';

      console.log('ğŸ” [AI-Bridge] æœç´¢ç«¯ç‚¹:', endpoint);

      // ä½¿ç”¨ç»Ÿä¸€çš„ç½‘ç»œé…ç½®ï¼Œå¼ºåˆ¶ç¦ç”¨ä»£ç†
      const networkConfig = AIConfigService.getAxiosConfig();

      const response = await axios.post(endpoint, requestBody, {
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${apiKey}`,
          'User-Agent': 'YY-AI-Assistant/1.0'
        },
        timeout: 30000,
        responseType: 'text', // ğŸ”§ å…³é”®ï¼šæ¥æ”¶æ–‡æœ¬æ ¼å¼ï¼Œç”¨äºè§£æSSE
        // ğŸš€ å¼ºåˆ¶ç¦ç”¨ä»£ç†ï¼Œç¡®ä¿ç›´è¿
        proxy: false,
        // ç¦ç”¨ç¯å¢ƒå˜é‡ä»£ç†
        httpAgent: new http.Agent({ keepAlive: true }),
        httpsAgent: new https.Agent({ keepAlive: true, rejectUnauthorized: false }),
        ...networkConfig
      });

      const searchTime = Date.now() - startTime;

      // ğŸ”§ è§£æSSEæ ¼å¼çš„å“åº”
      const responseText = response.data;
      console.log('ğŸ” [AI-Bridge] SSEå“åº”é•¿åº¦:', responseText.length, 'å­—ç¬¦');
      
      // æå–ç¬¬ä¸€ä¸ªdataå—ï¼ˆåŒ…å«æœç´¢ç»“æœï¼‰
      const lines = responseText.split('\n');
      let firstDataBlock = null;
      let aiSummaryChunks: string[] = [];
      
      for (const line of lines) {
        if (line.startsWith('data:')) {
          const jsonStr = line.substring(5).trim();
          if (!jsonStr) continue;
          
          try {
            const data = JSON.parse(jsonStr);
            
            // ç¬¬ä¸€ä¸ªåŒ…å«WebResultsçš„å—
            if (data.Result && data.Result.WebResults) {
              firstDataBlock = data;
            }
            
            // Choiceså—åŒ…å«AIæ€»ç»“
            if (data.Result && data.Result.Choices && data.Result.Choices.length > 0) {
              const chunk = data.Result.Choices[0].Delta?.Content || '';
              if (chunk) {
                aiSummaryChunks.push(chunk);
              }
            }
          } catch (e) {
            // å¿½ç•¥æ— æ•ˆJSON
            continue;
          }
        }
      }

      if (!firstDataBlock || !firstDataBlock.Result) {
        console.error('âŒ [AI-Bridge] æœªæ‰¾åˆ°æœ‰æ•ˆçš„æœç´¢ç»“æœ');
        throw new Error('æœç´¢APIè¿”å›æ ¼å¼é”™è¯¯');
      }

      const volcanoData = firstDataBlock;

      // è½¬æ¢ä¸ºç»Ÿä¸€æ ¼å¼
      const results: any[] = [];

      if (Array.isArray(volcanoData.Result.WebResults)) {
        volcanoData.Result.WebResults.forEach((item: any) => {
          results.push({
            title: item.Title || '',
            url: item.Url || '',
            snippet: item.Snippet || '',
            publishTime: item.PublishTime,
            source: item.Source,
            relevanceScore: item.RelevanceScore
          });
        });
      }

      // ğŸ”§ åˆå¹¶AIæ€»ç»“ï¼šä¼˜å…ˆä½¿ç”¨Summaryå­—æ®µï¼Œå¦åˆ™ä½¿ç”¨æµå¼Choicesæ‹¼æ¥çš„å†…å®¹
      const aiSummary = volcanoData.Result.Summary || aiSummaryChunks.join('') || '';
      
      const searchResponse: AiBridgeSearchResponse = {
        query: params.query,
        results: results,
        totalResults: results.length,
        searchTime: searchTime,
        aiSummary: aiSummary,
        suggestions: volcanoData.Result.Suggestions || [],
        relatedQueries: volcanoData.Result.RelatedQueries || []
      };

      console.log('ğŸ” [AI-Bridge] æœç´¢æˆåŠŸï¼Œè¿”å›', results.length, 'æ¡ç»“æœ');
      console.log('ğŸ” [AI-Bridge] AIæ€»ç»“é•¿åº¦:', aiSummary.length, 'å­—ç¬¦');
      return searchResponse;

    } catch (error: any) {
      console.error('ğŸ” [AI-Bridge] æœç´¢å¤±è´¥:', error.message);

      // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯æŠ›å‡ºé”™è¯¯
      return {
        query: params.query,
        results: [],
        totalResults: 0,
        searchTime: Date.now() - startTime,
        aiSummary: `æœç´¢å¤±è´¥: ${error.message}`
      };
    }
  }

  /**
   * ä»æ•°æ®åº“è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨
   */
  async getModels(): Promise<any[]> {
    try {
      // å¯¼å…¥AIæ¨¡å‹é…ç½®
      const { AIModelConfig } = await import('../../../models/ai-model-config.model');

      // ä»æ•°æ®åº“è·å–æ‰€æœ‰æ¿€æ´»çš„æ¨¡å‹
      const models = await AIModelConfig.findAll({
        where: {
          status: 'active'
        },
        attributes: ['id', 'name', 'displayName', 'provider', 'modelType', 'isDefault', 'endpointUrl'],
        order: [['isDefault', 'DESC'], ['name', 'ASC']]
      });

      // æ ¼å¼åŒ–è¿”å›ç»“æœ
      return models.map(model => ({
        id: model.id,
        name: model.name,
        displayName: model.displayName || model.name,
        provider: model.provider,
        modelType: model.modelType,
        isDefault: model.isDefault || false,
        endpointUrl: model.endpointUrl
      }));

    } catch (error) {
      console.error('âŒ [AI-Bridge] è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥:', error);

      // è¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨ä½œä¸ºå¤‡é€‰
      return [
        {
          id: 1,
          name: 'gpt-3.5-turbo',
          displayName: 'GPT-3.5 Turbo',
          provider: 'openai',
          modelType: 'chat',
          isDefault: true,
          endpointUrl: 'https://api.openai.com/v1'
        },
        {
          id: 2,
          name: 'gpt-4',
          displayName: 'GPT-4',
          provider: 'openai',
          modelType: 'chat',
          isDefault: false,
          endpointUrl: 'https://api.openai.com/v1'
        }
      ];
    }
  }
}

// Export a singleton instance of the service
export const aiBridgeService = new AIBridgeService();

