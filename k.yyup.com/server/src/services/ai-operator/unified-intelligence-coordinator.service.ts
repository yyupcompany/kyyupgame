/**
 * ç»Ÿä¸€æ™ºèƒ½å†³ç­–åè°ƒå™¨ (é‡æ„ç‰ˆ)
 * ä½¿ç”¨æ–°çš„å­æœåŠ¡æ¶æ„ï¼Œç®€åŒ–ä¸»é€»è¾‘ï¼Œæå‡å¯ç»´æŠ¤æ€§
 * é›†æˆAIBridgeServiceå’Œç¼“å­˜æœºåˆ¶
 */

import { intentRecognitionService } from './core/intent-recognition.service';
import { promptBuilderService } from './core/prompt-builder.service';
import { toolOrchestratorService } from './core/tool-orchestrator.service';
import { streamingService } from './core/streaming.service';
// import { multiRoundChatService } from './core/multi-round-chat.service'; // æš‚æœªä½¿ç”¨
import { memoryIntegrationService } from './core/memory-integration.service';

import { unifiedAIBridge } from '../unified-ai-bridge.service';
import { aiModelCacheService } from '../ai-model-cache.service';
import { getMemorySystem } from '../memory/six-dimension-memory.service';
import { logger } from '../../utils/logger';

/**
 * ç”¨æˆ·è¯·æ±‚æ¥å£
 */
export interface UserRequest {
  content: string;
  userId: string;
  conversationId: string;
  context?: any;
}

/**
 * å“åº”æ¥å£
 */
export interface IntelligenceResponse {
  success: boolean;
  message: string;
  data?: any;
  toolCalls?: any[];
  requiresMultiRound?: boolean;
  error?: string;
}

/**
 * ç»Ÿä¸€æ™ºèƒ½å†³ç­–åè°ƒå™¨ç±»
 */
export class UnifiedIntelligenceCoordinator {
  private static instance: UnifiedIntelligenceCoordinator;
  private initialized = false;
  private modelCacheService: typeof aiModelCacheService;
  private requestCache: Map<string, { response: string; timestamp: number }> = new Map();
  private cacheTimeout = 5 * 60 * 1000; // 5åˆ†é’Ÿç¼“å­˜

  private constructor() {
    this.modelCacheService = aiModelCacheService;
  }

  /**
   * è·å–å•ä¾‹å®ä¾‹
   */
  static getInstance(): UnifiedIntelligenceCoordinator {
    if (!UnifiedIntelligenceCoordinator.instance) {
      UnifiedIntelligenceCoordinator.instance = new UnifiedIntelligenceCoordinator();
    }
    return UnifiedIntelligenceCoordinator.instance;
  }

  /**
   * åˆå§‹åŒ–åè°ƒå™¨
   */
  async initialize(): Promise<void> {
    if (this.initialized) {
      return;
    }

    logger.info('ğŸš€ [åè°ƒå™¨] åˆå§‹åŒ–ç»Ÿä¸€æ™ºèƒ½å†³ç­–åè°ƒå™¨...');

    try {
      // åˆå§‹åŒ–æ¨¡å‹ç¼“å­˜
      await this.modelCacheService.initializeCache();

      // åˆå§‹åŒ–è®°å¿†ç³»ç»Ÿ
      const memorySystem = await getMemorySystem();
      memoryIntegrationService.setMemorySystem(memorySystem);

      // æ³¨å†Œå·¥å…·ï¼ˆè¿™é‡Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µæ³¨å†Œï¼‰
      // toolOrchestratorService.registerTool(...);

      this.initialized = true;
      logger.info('âœ… [åè°ƒå™¨] åˆå§‹åŒ–å®Œæˆ');
    } catch (error) {
      logger.error('âŒ [åè°ƒå™¨] åˆå§‹åŒ–å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†ç”¨æˆ·è¯·æ±‚ï¼ˆä¸»å…¥å£ï¼‰
   */
  async processRequest(request: UserRequest): Promise<IntelligenceResponse> {
    console.log(`ğŸ“¥ [åè°ƒå™¨] å¤„ç†è¯·æ±‚: ${request.content.substring(0, 50)}...`);

    try {
      // ç¡®ä¿å·²åˆå§‹åŒ–
      await this.initialize();

      // 1. æ„å›¾è¯†åˆ«
      const intentAnalysis = await intentRecognitionService.recognizeIntent(
        request.content,
        request.context
      );

      console.log(`ğŸ¯ [åè°ƒå™¨] æ„å›¾: ${intentAnalysis.intent}, å¤æ‚åº¦: ${intentAnalysis.complexity}`);

      // 2. æ£€ç´¢è®°å¿†ä¸Šä¸‹æ–‡
      const memoryContext = await memoryIntegrationService.retrieveMemoryContext(
        request.content,
        request.userId,
        {
          dimensions: ['core', 'episodic', 'semantic'],
          limit: 5
        }
      );

      console.log(`ğŸ§  [åè°ƒå™¨] æ£€ç´¢åˆ° ${memoryContext.items.length} æ¡è®°å¿†`);

      // 3. åˆ¤æ–­æ˜¯å¦éœ€è¦å·¥å…·
      const requiresTools = intentRecognitionService.requiresTools(intentAnalysis);

      if (requiresTools) {
        // éœ€è¦å·¥å…·çš„å¤æ‚è¯·æ±‚
        return await this.handleToolBasedRequest(request, intentAnalysis, memoryContext);
      } else {
        // ç®€å•å¯¹è¯è¯·æ±‚
        return await this.handleSimpleChat(request, intentAnalysis, memoryContext);
      }
    } catch (error) {
      console.error('âŒ [åè°ƒå™¨] å¤„ç†å¤±è´¥:', error);
      return {
        success: false,
        message: 'å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯',
        error: error instanceof Error ? error.message : String(error)
      };
    }
  }

  /**
   * å¤„ç†åŸºäºå·¥å…·çš„è¯·æ±‚
   */
  private async handleToolBasedRequest(
    request: UserRequest,
    intentAnalysis: any,
    memoryContext: any
  ): Promise<IntelligenceResponse> {
    console.log('ğŸ”§ [åè°ƒå™¨] å¤„ç†å·¥å…·è¯·æ±‚');

    try {
      // 1. ç¼–æ’å·¥å…·
      const toolPlan = await toolOrchestratorService.orchestrateTools(
        intentAnalysis,
        request.content
      );

      console.log(`ğŸ“‹ [åè°ƒå™¨] å·¥å…·è®¡åˆ’: ${toolPlan.tools.length} ä¸ªå·¥å…·`);

      // 2. æ‰§è¡Œå·¥å…·é“¾
      const toolResults = await toolOrchestratorService.executeToolChain(
        toolPlan,
        { userId: request.userId, conversationId: request.conversationId }
      );

      console.log(`âœ… [åè°ƒå™¨] å·¥å…·æ‰§è¡Œå®Œæˆ: ${toolResults.length} ä¸ªç»“æœ`);

      // 3. æ„å»ºæç¤ºè¯
      const systemPrompt = promptBuilderService.buildSystemPrompt({
        userRole: request.context?.userRole || 'user',
        memoryContext: memoryContext.items,
        tools: toolPlan.tools
      });

      const userPrompt = promptBuilderService.buildUserPrompt(
        request.content,
        {
          toolResults,
          pageContext: request.context?.pageContext
        }
      );

      // 4. è°ƒç”¨AIæ¨¡å‹
      const aiResponse = await this.callAIModel(
        systemPrompt,
        userPrompt,
        request.userId
      );

      return {
        success: true,
        message: aiResponse,
        toolCalls: toolPlan.tools,
        data: {
          toolResults,
          intentAnalysis
        }
      };
    } catch (error) {
      console.error('âŒ [åè°ƒå™¨] å·¥å…·è¯·æ±‚å¤„ç†å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†ç®€å•å¯¹è¯
   */
  private async handleSimpleChat(
    request: UserRequest,
    intentAnalysis: any,
    memoryContext: any
  ): Promise<IntelligenceResponse> {
    console.log('ğŸ’¬ [åè°ƒå™¨] å¤„ç†ç®€å•å¯¹è¯');

    try {
      // 1. æ„å»ºæç¤ºè¯
      const systemPrompt = promptBuilderService.buildSystemPrompt({
        userRole: request.context?.userRole || 'user',
        memoryContext: memoryContext.items
      });

      const userPrompt = promptBuilderService.buildUserPrompt(
        request.content,
        {
          pageContext: request.context?.pageContext
        }
      );

      // 2. è°ƒç”¨AIæ¨¡å‹
      const aiResponse = await this.callAIModel(
        systemPrompt,
        userPrompt,
        request.userId
      );

      return {
        success: true,
        message: aiResponse,
        data: {
          intentAnalysis,
          memoryContext: memoryContext.items
        }
      };
    } catch (error) {
      console.error('âŒ [åè°ƒå™¨] ç®€å•å¯¹è¯å¤„ç†å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * å¤„ç†æµå¼è¯·æ±‚
   */
  async processStreamRequest(
    request: UserRequest,
    res: any
  ): Promise<void> {
    console.log(`ğŸ“¡ [åè°ƒå™¨] å¤„ç†æµå¼è¯·æ±‚: ${request.content.substring(0, 50)}...`);

    try {
      // åˆå§‹åŒ–SSE
      streamingService.initializeSSE(res);

      // åˆ›å»ºæµåŒ…è£…å™¨
      const stream = streamingService.createStreamWrapper(res);

      // å‘é€è¿æ¥æˆåŠŸ
      stream.status('connected', 'è¿æ¥æˆåŠŸ');

      // ç¡®ä¿å·²åˆå§‹åŒ–
      await this.initialize();

      // 1. æ„å›¾è¯†åˆ«
      stream.progress(1, 5, 'æ­£åœ¨åˆ†ææ„å›¾...');
      const intentAnalysis = await intentRecognitionService.recognizeIntent(
        request.content,
        request.context
      );

      // 2. æ£€ç´¢è®°å¿†
      stream.progress(2, 5, 'æ­£åœ¨æ£€ç´¢è®°å¿†...');
      const memoryContext = await memoryIntegrationService.retrieveMemoryContext(
        request.content,
        request.userId
      );

      // 3. æ„å»ºæç¤ºè¯
      stream.progress(3, 5, 'æ­£åœ¨æ„å»ºæç¤ºè¯...');
      const systemPrompt = promptBuilderService.buildSystemPrompt({
        userRole: request.context?.userRole || 'user',
        memoryContext: memoryContext.items
      });

      const userPrompt = promptBuilderService.buildUserPrompt(request.content);

      // 4. æµå¼è°ƒç”¨AI
      stream.progress(4, 5, 'æ­£åœ¨ç”Ÿæˆå›ç­”...');
      await this.streamAIResponse(systemPrompt, userPrompt, request.userId, stream);

      // 5. å®Œæˆ
      stream.complete({
        intentAnalysis,
        memoryCount: memoryContext.items.length
      });
    } catch (error) {
      console.error('âŒ [åè°ƒå™¨] æµå¼è¯·æ±‚å¤„ç†å¤±è´¥:', error);
      streamingService.createStreamWrapper(res).error(
        error instanceof Error ? error : new Error(String(error))
      );
    }
  }

  /**
   * è°ƒç”¨AIæ¨¡å‹
   */
  private async callAIModel(
    systemPrompt: string,
    userPrompt: string,
    userId: string
  ): Promise<string> {
    try {
      // æ£€æŸ¥ç¼“å­˜
      const cacheKey = `${userId}:${systemPrompt.substring(0, 50)}:${userPrompt.substring(0, 50)}`;
      const cached = this.requestCache.get(cacheKey);
      if (cached && Date.now() - cached.timestamp < this.cacheTimeout) {
        logger.info('âœ… [åè°ƒå™¨] ä½¿ç”¨ç¼“å­˜å“åº”');
        return cached.response;
      }

      // è·å–é»˜è®¤æ¨¡å‹
      const model = await this.modelCacheService.getDefaultModel();
      if (!model) {
        throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„AIæ¨¡å‹');
      }

      logger.info(`ğŸ¤– [åè°ƒå™¨] ä½¿ç”¨æ¨¡å‹: ${model.name}`);

      // æ„å»ºæ¶ˆæ¯
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        { role: 'user' as const, content: userPrompt }
      ];

      // è°ƒç”¨AIæ¨¡å‹
      const response = await unifiedAIBridge.chat({
        model: model.name,
        messages,
        temperature: 0.7,
        max_tokens: 2000
      });

      const content = response.data?.content || response.data?.message || '';

      // æ›´æ–°ç¼“å­˜
      this.requestCache.set(cacheKey, { response: content, timestamp: Date.now() });

      return content;
    } catch (error) {
      logger.error('âŒ [åè°ƒå™¨] AIæ¨¡å‹è°ƒç”¨å¤±è´¥:', error);

      // é™çº§ç­–ç•¥ï¼šè¿”å›å‹å¥½é”™è¯¯æ¶ˆæ¯
      return this.getFallbackResponse(error);
    }
  }

  /**
   * è·å–é™çº§å“åº”
   */
  private getFallbackResponse(error: any): string {
    logger.warn('âš ï¸ [åè°ƒå™¨] ä½¿ç”¨é™çº§å“åº”');

    const errorMessage = error instanceof Error ? error.message : String(error);

    if (errorMessage.includes('timeout') || errorMessage.includes('è¶…æ—¶')) {
      return 'æŠ±æ­‰ï¼ŒAIæœåŠ¡å“åº”è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•ã€‚';
    }

    if (errorMessage.includes('rate limit') || errorMessage.includes('é™æµ')) {
      return 'æŠ±æ­‰ï¼Œå½“å‰è¯·æ±‚è¿‡å¤šï¼Œè¯·ç¨åé‡è¯•ã€‚';
    }

    return 'æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•ã€‚';
  }

  /**
   * æµå¼è°ƒç”¨AIæ¨¡å‹
   */
  private async streamAIResponse(
    systemPrompt: string,
    userPrompt: string,
    userId: string,
    stream: any
  ): Promise<void> {
    try {
      // è·å–é»˜è®¤æ¨¡å‹
      const model = await this.modelCacheService.getDefaultModel();
      if (!model) {
        throw new Error('æœªæ‰¾åˆ°å¯ç”¨çš„AIæ¨¡å‹');
      }

      logger.info(`ğŸ¤– [åè°ƒå™¨] æµå¼è°ƒç”¨æ¨¡å‹: ${model.name}`);

      // æ„å»ºæ¶ˆæ¯
      const messages = [
        { role: 'system' as const, content: systemPrompt },
        { role: 'user' as const, content: userPrompt }
      ];

      // è°ƒç”¨AIæ¨¡å‹ï¼ˆéæµå¼ï¼Œå› ä¸ºUnifiedAIBridgeçš„æµå¼æ”¯æŒéœ€è¦ç‰¹æ®Šå¤„ç†ï¼‰
      const response = await unifiedAIBridge.chat({
        model: model.name,
        messages,
        temperature: 0.7,
        max_tokens: 2000
      });

      // æ¨¡æ‹Ÿæµå¼å‘é€
      const content = response.data?.content || response.data?.message || '';
      const chunks = content.match(/.{1,50}/g) || [content];

      for (const chunk of chunks) {
        stream.send('message', { content: chunk });
        await new Promise(resolve => setTimeout(resolve, 50));
      }
    } catch (error) {
      logger.error('âŒ [åè°ƒå™¨] æµå¼AIè°ƒç”¨å¤±è´¥:', error);
      throw error;
    }
  }

  /**
   * æ¸…ç†è¿‡æœŸç¼“å­˜
   */
  clearExpiredCache(): void {
    const now = Date.now();
    for (const [key, value] of this.requestCache.entries()) {
      if (now - value.timestamp > this.cacheTimeout) {
        this.requestCache.delete(key);
      }
    }
    logger.info(`ğŸ§¹ [åè°ƒå™¨] æ¸…ç†è¿‡æœŸç¼“å­˜ï¼Œå‰©ä½™: ${this.requestCache.size} æ¡`);
  }

  /**
   * æ¸…ç©ºæ‰€æœ‰ç¼“å­˜
   */
  clearAllCache(): void {
    this.requestCache.clear();
    logger.info('ğŸ§¹ [åè°ƒå™¨] å·²æ¸…ç©ºæ‰€æœ‰ç¼“å­˜');
  }

  /**
   * è·å–ç¼“å­˜ç»Ÿè®¡
   */
  getCacheStats(): { size: number; timeout: number } {
    return {
      size: this.requestCache.size,
      timeout: this.cacheTimeout
    };
  }

  /**
   * è·å–æœåŠ¡çŠ¶æ€
   */
  getStatus(): {
    initialized: boolean;
    cacheSize: number;
    modelCacheInitialized: boolean;
  } {
    return {
      initialized: this.initialized,
      cacheSize: this.requestCache.size,
      modelCacheInitialized: this.modelCacheService ? true : false
    };
  }
}

// å¯¼å‡ºå•ä¾‹
export const unifiedIntelligenceCoordinator = UnifiedIntelligenceCoordinator.getInstance();

