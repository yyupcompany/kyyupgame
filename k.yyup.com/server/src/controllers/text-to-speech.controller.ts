import { Request, Response } from 'express';
import { aiBridgeService } from '../services/ai/bridge/ai-bridge.service';
import { AiBridgeTextToSpeechParams } from '../services/ai/bridge/ai-bridge.types';
import AIModelConfig from '../models/ai-model-config.model';

/**
 * æ–‡å­—è½¬è¯­éŸ³æ§åˆ¶å™¨
 */
export class TextToSpeechController {
  private aiBridgeService = aiBridgeService;

  constructor() {
    // Use the singleton instance
  }

  /**
   * ç”Ÿæˆè¯­éŸ³
   */
  public generateSpeech = async (req: Request, res: Response): Promise<void> => {
    try {
      const { text, voice = 'nova', speed = 1.0, format = 'mp3' } = req.body;

      // éªŒè¯å‚æ•°
      if (!text || typeof text !== 'string') {
        res.status(400).json({
          success: false,
          message: 'æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º'
        });
        return;
      }

      if (text.length > 4096) {
        res.status(400).json({
          success: false,
          message: 'æ–‡æœ¬å†…å®¹ä¸èƒ½è¶…è¿‡4096ä¸ªå­—ç¬¦'
        });
        return;
      }

      console.log('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] å¼€å§‹ç”Ÿæˆè¯­éŸ³:', {
        textLength: text.length,
        voice,
        speed,
        format
      });

      // æŸ¥è¯¢TTSæ¨¡å‹é…ç½®
      const ttsModel = await AIModelConfig.findOne({
        where: {
          modelType: 'speech',
          status: 'active'
        }
      });

      // æ„å»ºè¯·æ±‚å‚æ•°
      const params: AiBridgeTextToSpeechParams = {
        model: ttsModel?.name || 'tts-1',
        input: text,
        voice: voice,
        response_format: format as 'mp3' | 'opus' | 'aac' | 'flac',
        speed: speed
      };

      // è°ƒç”¨AI BridgeæœåŠ¡
      let audioResult;
      if (ttsModel && ttsModel.endpointUrl && ttsModel.apiKey) {
        console.log('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] ä½¿ç”¨è‡ªå®šä¹‰TTSæ¨¡å‹é…ç½®');
        audioResult = await this.aiBridgeService.textToSpeech(params, {
          endpointUrl: ttsModel.endpointUrl,
          apiKey: ttsModel.apiKey
        });
      } else {
        console.log('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] ä½¿ç”¨é»˜è®¤TTSé…ç½®');
        audioResult = await this.aiBridgeService.textToSpeech(params);
      }

      console.log('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] è¯­éŸ³ç”ŸæˆæˆåŠŸ');

      // è®¾ç½®å“åº”å¤´ - æ”¯æŒéŸ³é¢‘æ’­æ”¾å’ŒRangeè¯·æ±‚
      res.setHeader('Content-Type', audioResult.contentType);
      res.setHeader('Content-Length', audioResult.audioData.length.toString());
      res.setHeader('Accept-Ranges', 'bytes');
      res.setHeader('Cache-Control', 'public, max-age=3600');

      // ä¸è®¾ç½® Content-Dispositionï¼Œè®©æµè§ˆå™¨å¯ä»¥ç›´æ¥æ’­æ”¾
      // å¦‚æœéœ€è¦ä¸‹è½½ï¼Œå‰ç«¯ä¼šé€šè¿‡ download å±æ€§å¤„ç†

      // è¿”å›éŸ³é¢‘æ•°æ®
      res.send(audioResult.audioData);
    } catch (error) {
      console.error('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] ç”Ÿæˆå¤±è´¥:', error);
      res.status(500).json({
        success: false,
        message: 'è¯­éŸ³ç”Ÿæˆå¤±è´¥',
        error: error instanceof Error ? error.message : 'æœªçŸ¥é”™è¯¯'
      });
    }
  };

  /**
   * è·å–å¯ç”¨çš„éŸ³è‰²åˆ—è¡¨
   */
  public getVoices = async (_req: Request, res: Response): Promise<void> => {
    try {
      const voices = [
        {
          id: 'alloy',
          name: 'å¥³å£°-æ¸©æŸ”',
          description: 'æ¸©æŸ”äº²åˆ‡çš„å¥³å£°',
          language: 'zh-CN'
        },
        {
          id: 'nova',
          name: 'å¥³å£°-æ´»æ³¼',
          description: 'æ´»æ³¼å¼€æœ—çš„å¥³å£°',
          language: 'zh-CN'
        },
        {
          id: 'shimmer',
          name: 'å¥³å£°-ä¸“ä¸š',
          description: 'ä¸“ä¸šç¨³é‡çš„å¥³å£°',
          language: 'zh-CN'
        },
        {
          id: 'echo',
          name: 'ç”·å£°-æ²‰ç¨³',
          description: 'æ²‰ç¨³å¤§æ°”çš„ç”·å£°',
          language: 'zh-CN'
        },
        {
          id: 'fable',
          name: 'ç”·å£°-å¹´è½»',
          description: 'å¹´è½»æ´»åŠ›çš„ç”·å£°',
          language: 'zh-CN'
        },
        {
          id: 'onyx',
          name: 'ç”·å£°-ç£æ€§',
          description: 'ç£æ€§æ·±æ²‰çš„ç”·å£°',
          language: 'zh-CN'
        }
      ];

      res.json({
        success: true,
        data: voices
      });
    } catch (error) {
      console.error('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] è·å–éŸ³è‰²åˆ—è¡¨å¤±è´¥:', error);
      res.status(500).json({
        success: false,
        message: 'è·å–éŸ³è‰²åˆ—è¡¨å¤±è´¥'
      });
    }
  };

  /**
   * è·å–TTSæ¨¡å‹é…ç½®
   */
  public getConfig = async (_req: Request, res: Response): Promise<void> => {
    try {
      const ttsModel = await AIModelConfig.findOne({
        where: {
          modelType: 'speech',
          status: 'active'
        }
      });

      res.json({
        success: true,
        data: {
          hasConfig: !!ttsModel,
          modelName: ttsModel?.name || 'tts-1',
          maxLength: 4096,
          supportedFormats: ['mp3', 'opus', 'aac', 'flac'],
          speedRange: {
            min: 0.25,
            max: 4.0,
            default: 1.0
          }
        }
      });
    } catch (error) {
      console.error('ğŸ”Š [æ–‡å­—è½¬è¯­éŸ³] è·å–é…ç½®å¤±è´¥:', error);
      res.status(500).json({
        success: false,
        message: 'è·å–é…ç½®å¤±è´¥'
      });
    }
  };
}

export default new TextToSpeechController();

