/**
 * ğŸ« ç§»åŠ¨ç«¯AIåŠ©æ‰‹çŠ¶æ€ç®¡ç†
 * 
 * åŸºäº 05-APIé›†æˆè¯´æ˜.md çš„AIæœåŠ¡è®¾è®¡
 * ç®¡ç†AIå¯¹è¯ã€è¯­éŸ³è¯†åˆ«ã€æ™ºèƒ½æ¨èç­‰åŠŸèƒ½
 */

import { defineStore } from 'pinia'
import { ref, computed } from 'vue'
import { MobileAPIService } from '../services/mobile-api.service'

const mobileAPIService = new MobileAPIService()

export interface ChatMessage {
  id: string
  type: 'user' | 'ai' | 'system'
  content: string
  timestamp: Date
  status?: 'sending' | 'sent' | 'delivered' | 'failed'
  actions?: MessageAction[]
  metadata?: Record<string, any>
}

export interface MessageAction {
  id: string
  title: string
  type: 'link' | 'action' | 'form'
  payload?: any
}

export interface ChatSession {
  id: string
  title: string
  messages: ChatMessage[]
  createdAt: Date
  updatedAt: Date
  context?: Record<string, any>
}

export interface VoiceRecognition {
  isSupported: boolean
  isListening: boolean
  isProcessing: boolean
  error?: string
  transcript?: string
  confidence?: number
}

export interface AiCapabilities {
  chat: boolean
  voice: boolean
  imageRecognition: boolean
  documentAnalysis: boolean
  smartRecommendation: boolean
  contextAware: boolean
}

export const useAiAssistantStore = defineStore('ai-assistant', () => {
  // ==================== çŠ¶æ€æ•°æ® ====================

  // èŠå¤©ä¼šè¯
  const currentSession = ref<ChatSession | null>(null)
  const chatSessions = ref<ChatSession[]>([])
  const isLoading = ref(false)
  const isTyping = ref(false)

  // è¯­éŸ³è¯†åˆ«
  const voiceRecognition = ref<VoiceRecognition>({
    isSupported: 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window,
    isListening: false,
    isProcessing: false
  })

  // AIèƒ½åŠ›
  const capabilities = ref<AiCapabilities>({
    chat: true,
    voice: true,
    imageRecognition: true,
    documentAnalysis: true,
    smartRecommendation: true,
    contextAware: true
  })

  // è®¾ç½®
  const settings = ref({
    autoSpeech: false,          // è‡ªåŠ¨è¯­éŸ³æ’­æ”¾
    voiceSpeed: 1.0,           // è¯­éŸ³æ’­æ”¾é€Ÿåº¦
    voiceVolume: 0.8,          // è¯­éŸ³éŸ³é‡
    language: 'zh-CN',         // è¯­è¨€è®¾ç½®
    theme: 'auto',             // ä¸»é¢˜
    contextMemory: true,       // ä¸Šä¸‹æ–‡è®°å¿†
    smartSuggestions: true,    // æ™ºèƒ½å»ºè®®
    hapticFeedback: true       // è§¦è§‰åé¦ˆ
  })

  // æ™ºèƒ½å»ºè®®
  const suggestions = ref<string[]>([])
  const quickReplies = ref<string[]>([])

  // çŠ¶æ€æ ‡è®°
  const isVisible = ref(false)
  const isMinimized = ref(false)
  const hasUnreadMessages = ref(false)

  // è¯­éŸ³ç›¸å…³
  const speechRecognition = ref<any>(null)
  const speechSynthesis = ref<any>(null)

  // ==================== è®¡ç®—å±æ€§ ====================

  const hasActiveSessions = computed(() => chatSessions.value.length > 0)
  
  const currentSessionMessages = computed(() => 
    currentSession.value?.messages || []
  )

  const unreadCount = computed(() => {
    let count = 0
    chatSessions.value.forEach(session => {
      session.messages.forEach(message => {
        if (message.type === 'ai' && message.status !== 'delivered') {
          count++
        }
      })
    })
    return count
  })

  const canUseVoice = computed(() => 
    capabilities.value.voice && voiceRecognition.value.isSupported
  )

  const isVoiceActive = computed(() => 
    voiceRecognition.value.isListening || voiceRecognition.value.isProcessing
  )

  const lastUserMessage = computed(() => {
    const messages = currentSessionMessages.value
    for (let i = messages.length - 1; i >= 0; i--) {
      if (messages[i].type === 'user') {
        return messages[i]
      }
    }
    return null
  })

  const contextData = computed(() => {
    if (!settings.value.contextMemory) return {}
    
    return {
      sessionId: currentSession.value?.id,
      messageCount: currentSessionMessages.value.length,
      lastActivity: currentSession.value?.updatedAt,
      userPreferences: getUserPreferences()
    }
  })

  // ==================== æ–¹æ³• ====================

  // åˆå§‹åŒ–AIåŠ©æ‰‹
  const initialize = async () => {
    try {
      // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
      await initializeSpeechRecognition()
      
      // åˆå§‹åŒ–è¯­éŸ³åˆæˆ
      initializeSpeechSynthesis()
      
      // åŠ è½½èŠå¤©å†å²
      await loadChatHistory()
      
      // æ£€æŸ¥AIæœåŠ¡çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰
      await checkAiServiceStatus()
      
      console.log('AIåŠ©æ‰‹åˆå§‹åŒ–å®Œæˆ')
    } catch (error) {
      console.error('AIåŠ©æ‰‹åˆå§‹åŒ–å¤±è´¥:', error)
    }
  }

  // åˆå§‹åŒ–è¯­éŸ³è¯†åˆ«
  const initializeSpeechRecognition = async () => {
    if (!voiceRecognition.value.isSupported) return

    try {
      const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition
      speechRecognition.value = new SpeechRecognition()
      
      speechRecognition.value.continuous = false
      speechRecognition.value.interimResults = true
      speechRecognition.value.lang = settings.value.language

      speechRecognition.value.onstart = () => {
        voiceRecognition.value.isListening = true
        voiceRecognition.value.error = undefined
      }

      speechRecognition.value.onresult = (event: any) => {
        const transcript = Array.from(event.results)
          .map((result: any) => result[0].transcript)
          .join('')
        
        voiceRecognition.value.transcript = transcript
        voiceRecognition.value.confidence = event.results[0]?.[0]?.confidence || 0
      }

      speechRecognition.value.onend = () => {
        voiceRecognition.value.isListening = false
        voiceRecognition.value.isProcessing = false
      }

      speechRecognition.value.onerror = (event: any) => {
        voiceRecognition.value.error = event.error
        voiceRecognition.value.isListening = false
        voiceRecognition.value.isProcessing = false
      }

    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«åˆå§‹åŒ–å¤±è´¥:', error)
      voiceRecognition.value.isSupported = false
    }
  }

  // åˆå§‹åŒ–è¯­éŸ³åˆæˆ
  const initializeSpeechSynthesis = () => {
    if ('speechSynthesis' in window) {
      speechSynthesis.value = window.speechSynthesis
    }
  }

  // æ£€æŸ¥AIæœåŠ¡çŠ¶æ€ï¼ˆç®€åŒ–ç‰ˆï¼‰
  const checkAiServiceStatus = async () => {
    try {
      // ä½¿ç”¨ç§»åŠ¨ç«¯APIæœåŠ¡æ£€æŸ¥ä¸“å®¶åˆ—è¡¨
      const expertList = await mobileAPIService.getSmartExpertList()
      
      capabilities.value = {
        ...capabilities.value,
        chat: true,
        smartRecommendation: true,
        contextAware: true
      }
      
      console.log('å‘ç°å¯ç”¨ä¸“å®¶ï¼š', expertList.data?.total || 0, 'ä¸ª')
      return true
    } catch (error) {
      console.error('ç§»åŠ¨ç«¯AIæœåŠ¡çŠ¶æ€æ£€æŸ¥å¤±è´¥:', error)
      return false
    }
  }

  // åˆ›å»ºæ–°ä¼šè¯
  const createSession = () => {
    const session: ChatSession = {
      id: generateSessionId(),
      title: `å¯¹è¯ ${chatSessions.value.length + 1}`,
      messages: [],
      createdAt: new Date(),
      updatedAt: new Date()
    }

    chatSessions.value.unshift(session)
    currentSession.value = session
    
    return session
  }

  // å‘é€æ¶ˆæ¯
  const sendMessage = async (content: string, type: 'text' | 'voice' = 'text') => {
    if (!content.trim()) return null

    // ç¡®ä¿æœ‰æ´»åŠ¨ä¼šè¯
    if (!currentSession.value) {
      createSession()
    }

    const session = currentSession.value!
    
    // åˆ›å»ºç”¨æˆ·æ¶ˆæ¯
    const userMessage: ChatMessage = {
      id: generateMessageId(),
      type: 'user',
      content: content.trim(),
      timestamp: new Date(),
      status: 'sending',
      metadata: { inputType: type }
    }

    // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
    session.messages.push(userMessage)
    session.updatedAt = new Date()

    try {
      isLoading.value = true
      isTyping.value = true
      
      // æ ‡è®°æ¶ˆæ¯ä¸ºå·²å‘é€
      userMessage.status = 'sent'

      // è°ƒç”¨ç§»åŠ¨ç«¯AIæœåŠ¡ï¼Œä½¿ç”¨Smart Chatæ¥å£
      const response = await mobileAPIService.callSmartExpert({
        expert_id: 'activity_planner', // é»˜è®¤ä½¿ç”¨æ´»åŠ¨ç­–åˆ’ä¸“å®¶ï¼Œå¯æ ¹æ®å†…å®¹æ™ºèƒ½é€‰æ‹©
        task: content,
        context: `ä¼šè¯ID: ${session.id}, ç”¨æˆ·éœ€æ±‚: ${content}`
      })

      // åˆ›å»ºAIå›å¤æ¶ˆæ¯
      const aiMessage: ChatMessage = {
        id: generateMessageId(),
        type: 'ai',
        content: response.advice || 'æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨æ— æ³•å›å¤æ‚¨çš„é—®é¢˜ï¼Œè¯·ç¨åå†è¯•ã€‚',
        timestamp: new Date(),
        status: 'delivered',
        actions: [], // ç›®å‰ä¸“å®¶ç³»ç»Ÿä¸è¿”å›actions
        metadata: {
          expert_id: response.expert_id,
          expert_name: response.expert_name,
          timestamp: response.timestamp,
          error: response.error
        }
      }

      // æ·»åŠ AIå›å¤
      session.messages.push(aiMessage)
      session.updatedAt = new Date()

      // æ›´æ–°å»ºè®®
      if (response.suggestions) {
        suggestions.value = response.suggestions
      }

      // æ›´æ–°å¿«æ·å›å¤
      if (response.quickReplies) {
        quickReplies.value = response.quickReplies
      }

      // è‡ªåŠ¨è¯­éŸ³æ’­æ”¾
      if (settings.value.autoSpeech && type === 'voice') {
        await speakText(response.content)
      }

      // ä¿å­˜ä¼šè¯
      await saveChatHistory()

      return {
        success: true,
        content: response.content,
        actions: response.actions,
        suggestions: response.suggestions
      }

    } catch (error) {
      console.error('å‘é€æ¶ˆæ¯å¤±è´¥:', error)
      
      userMessage.status = 'failed'
      
      // æ·»åŠ é”™è¯¯æ¶ˆæ¯
      const errorMessage: ChatMessage = {
        id: generateMessageId(),
        type: 'system',
        content: 'æŠ±æ­‰ï¼Œæ¶ˆæ¯å‘é€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•ã€‚',
        timestamp: new Date()
      }
      
      session.messages.push(errorMessage)

      return {
        success: false,
        error: error.message
      }

    } finally {
      isLoading.value = false
      isTyping.value = false
    }
  }

  // å¼€å§‹è¯­éŸ³è¯†åˆ«
  const startVoiceRecognition = async () => {
    if (!canUseVoice.value || voiceRecognition.value.isListening) return

    try {
      voiceRecognition.value.isProcessing = true
      await speechRecognition.value.start()
    } catch (error) {
      console.error('è¯­éŸ³è¯†åˆ«å¯åŠ¨å¤±è´¥:', error)
      voiceRecognition.value.error = error.message
      voiceRecognition.value.isProcessing = false
    }
  }

  // åœæ­¢è¯­éŸ³è¯†åˆ«
  const stopVoiceRecognition = () => {
    if (speechRecognition.value && voiceRecognition.value.isListening) {
      speechRecognition.value.stop()
    }
  }

  // è¯­éŸ³è½¬æ–‡å­—å¹¶å‘é€
  const processVoiceInput = async () => {
    if (!voiceRecognition.value.transcript) return

    const transcript = voiceRecognition.value.transcript
    voiceRecognition.value.transcript = undefined

    return await sendMessage(transcript, 'voice')
  }

  // æ–‡å­—è½¬è¯­éŸ³
  const speakText = async (text: string) => {
    if (!speechSynthesis.value || !text) return

    return new Promise((resolve, reject) => {
      const utterance = new SpeechSynthesisUtterance(text)
      
      utterance.lang = settings.value.language
      utterance.rate = settings.value.voiceSpeed
      utterance.volume = settings.value.voiceVolume

      utterance.onend = () => resolve(true)
      utterance.onerror = (error) => reject(error)

      speechSynthesis.value.speak(utterance)
    })
  }

  // è·å–æ™ºèƒ½å»ºè®®
  const getSmartSuggestions = async (context?: string) => {
    if (!settings.value.smartSuggestions) return []

    try {
      const response = await aiApi.getSuggestions({
        context: context || getCurrentContext(),
        sessionId: currentSession.value?.id,
        userPreferences: getUserPreferences()
      })

      suggestions.value = response.suggestions
      return response.suggestions

    } catch (error) {
      console.error('è·å–æ™ºèƒ½å»ºè®®å¤±è´¥:', error)
      return []
    }
  }

  // è·å–å½“å‰ä¸Šä¸‹æ–‡
  const getCurrentContext = () => {
    const recentMessages = currentSessionMessages.value.slice(-5)
    return recentMessages.map(msg => ({
      type: msg.type,
      content: msg.content.slice(0, 100)
    }))
  }

  // è·å–ç”¨æˆ·åå¥½
  const getUserPreferences = () => {
    return {
      language: settings.value.language,
      preferredResponseLength: 'medium',
      topics: extractUserTopics(),
      interactionStyle: 'friendly'
    }
  }

  // æå–ç”¨æˆ·è¯é¢˜
  const extractUserTopics = () => {
    const topics = new Set<string>()
    
    chatSessions.value.forEach(session => {
      session.messages.forEach(message => {
        if (message.type === 'user') {
          // ç®€å•çš„å…³é”®è¯æå–
          const keywords = message.content
            .toLowerCase()
            .match(/[^\s\.,!?;:]+/g) || []
          
          keywords.forEach(keyword => {
            if (keyword.length > 3) {
              topics.add(keyword)
            }
          })
        }
      })
    })

    return Array.from(topics).slice(0, 10)
  }

  // æ¸…ç©ºå½“å‰ä¼šè¯
  const clearCurrentSession = () => {
    if (currentSession.value) {
      currentSession.value.messages = []
      currentSession.value.updatedAt = new Date()
    }
    suggestions.value = []
    quickReplies.value = []
  }

  // åˆ é™¤ä¼šè¯
  const deleteSession = (sessionId: string) => {
    const index = chatSessions.value.findIndex(s => s.id === sessionId)
    if (index > -1) {
      chatSessions.value.splice(index, 1)
      
      if (currentSession.value?.id === sessionId) {
        currentSession.value = chatSessions.value[0] || null
      }
      
      saveChatHistory()
    }
  }

  // åŠ è½½èŠå¤©å†å²
  const loadChatHistory = async () => {
    try {
      const stored = localStorage.getItem('ai-chat-history')
      if (stored) {
        const data = JSON.parse(stored)
        chatSessions.value = data.sessions.map((session: any) => ({
          ...session,
          createdAt: new Date(session.createdAt),
          updatedAt: new Date(session.updatedAt),
          messages: session.messages.map((message: any) => ({
            ...message,
            timestamp: new Date(message.timestamp)
          }))
        }))

        if (chatSessions.value.length > 0) {
          currentSession.value = chatSessions.value[0]
        }
      }
    } catch (error) {
      console.error('åŠ è½½èŠå¤©å†å²å¤±è´¥:', error)
    }
  }

  // ä¿å­˜èŠå¤©å†å²
  const saveChatHistory = async () => {
    try {
      const data = {
        sessions: chatSessions.value,
        settings: settings.value,
        lastSaved: new Date()
      }
      
      localStorage.setItem('ai-chat-history', JSON.stringify(data))
    } catch (error) {
      console.error('ä¿å­˜èŠå¤©å†å²å¤±è´¥:', error)
    }
  }

  // ç”Ÿæˆä¼šè¯ID
  const generateSessionId = () => {
    return `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  // ç”Ÿæˆæ¶ˆæ¯ID
  const generateMessageId = () => {
    return `msg_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`
  }

  // æ›´æ–°è®¾ç½®
  const updateSettings = (newSettings: Partial<typeof settings.value>) => {
    settings.value = { ...settings.value, ...newSettings }
    saveChatHistory()
  }

  // æ˜¾ç¤º/éšè—åŠ©æ‰‹
  const showAssistant = () => {
    isVisible.value = true
    hasUnreadMessages.value = false
  }

  const hideAssistant = () => {
    isVisible.value = false
  }

  // æœ€å°åŒ–/æœ€å¤§åŒ–
  const minimizeAssistant = () => {
    isMinimized.value = true
  }

  const maximizeAssistant = () => {
    isMinimized.value = false
  }

  // æ¸…ç†èµ„æº
  const cleanup = () => {
    if (speechRecognition.value) {
      speechRecognition.value.stop()
    }
    
    if (speechSynthesis.value) {
      speechSynthesis.value.cancel()
    }
  }

  // ==================== è¿”å› ====================

  return {
    // çŠ¶æ€
    currentSession,
    chatSessions,
    isLoading,
    isTyping,
    voiceRecognition,
    capabilities,
    settings,
    suggestions,
    quickReplies,
    isVisible,
    isMinimized,
    hasUnreadMessages,

    // è®¡ç®—å±æ€§
    hasActiveSessions,
    currentSessionMessages,
    unreadCount,
    canUseVoice,
    isVoiceActive,
    lastUserMessage,
    contextData,

    // æ–¹æ³•
    initialize,
    createSession,
    sendMessage,
    startVoiceRecognition,
    stopVoiceRecognition,
    processVoiceInput,
    speakText,
    getSmartSuggestions,
    clearCurrentSession,
    deleteSession,
    loadChatHistory,
    saveChatHistory,
    updateSettings,
    showAssistant,
    hideAssistant,
    minimizeAssistant,
    maximizeAssistant,
    cleanup
  }
})

export default useAiAssistantStore