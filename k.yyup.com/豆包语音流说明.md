# è±†åŒ…è¯­éŸ³æµåŒå‘è¯­éŸ³ç³»ç»Ÿè¯´æ˜æ–‡æ¡£

## ğŸ“– æ¦‚è¿°

æœ¬æ–‡æ¡£è¯¦ç»†è¯´æ˜æ–°åª’ä½“ä¸­å¿ƒè§†é¢‘åˆ¶ä½œé…éŸ³åŠŸèƒ½çš„å®Œæ•´å®ç°æ–¹æ¡ˆï¼ŒåŒ…æ‹¬è±†åŒ…å¤§æ¨¡å‹é…ç½®ã€å‰åç«¯åŒå‘è¯­éŸ³æµå®ç°ã€WebSocketåè®®è¯¦è§£ç­‰æŠ€æœ¯ç»†èŠ‚ã€‚

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ•´ä½“æ¶æ„å›¾
```
å‰ç«¯ (Vue3) â†’ APIç½‘å…³ â†’ AI Bridge Service â†’ TTS V3åŒå‘æµæœåŠ¡ â†’ è±†åŒ…TTS API
     â†“              â†“              â†“                    â†“              â†“
  UIç•Œé¢ç»„ä»¶    HTTP/WSè¯·æ±‚    ç»Ÿä¸€AIæ¥å£        WebSocketåè®®      éŸ³é¢‘åˆæˆ
  å‚æ•°é…ç½®      å‚æ•°éªŒè¯      æ¨¡å‹è·¯ç”±          å®æ—¶é€šä¿¡          å®æ—¶æµå¼è¿”å›
```

### æ ¸å¿ƒç»„ä»¶è¯´æ˜

1. **å‰ç«¯ç•Œé¢**: `TextToSpeech.vue` - ç”¨æˆ·äº¤äº’ç•Œé¢
2. **APIæ§åˆ¶å™¨**: `text-to-speech.controller.ts` - è¯·æ±‚éªŒè¯å’Œè·¯ç”±
3. **AIæ¡¥æ¥æœåŠ¡**: `ai-bridge.service.ts` - ç»Ÿä¸€AIæ¨¡å‹æ¥å£
4. **TTSåŒå‘æµæœåŠ¡**: `tts-v3-bidirection.service.ts` - WebSocketå®æ—¶é€šä¿¡
5. **è±†åŒ…TTS API**: ç«å±±å¼•æ“è¯­éŸ³åˆæˆæœåŠ¡

## ğŸ”§ å¤§æ¨¡å‹é…ç½®

### 1. ç¯å¢ƒå˜é‡é…ç½®

åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®è±†åŒ…TTSç›¸å…³å‚æ•°ï¼š

```bash
# è±†åŒ…TTSåŸºç¡€é…ç½®
VOLCENGINE_ACCESS_KEY=your_access_key_here
VOLCENGINE_SECRET_KEY=your_secret_key_here
VOLCENGINE_APP_KEY=your_app_key_here
VOLCENGINE_UNIT_ID=your_unit_id_here

# TTSæœåŠ¡é…ç½®
TTS_API_URL=https://openspeech.bytedance.com/api/v1/tts
TTS_WS_URL=wss://openspeech.bytedance.com/api/v1/tts/ws

# æ¨¡å‹èµ„æºé…ç½®
TTS_MODEL_RESOURCE_ID=your_resource_id_here
TTS_CLUSTER=default
TTS_ENABLE_PROFANITY_FILTER=true
```

### 2. æ¨¡å‹èµ„æºé…ç½®

åœ¨TTS V3æœåŠ¡ä¸­é…ç½®æ¨¡å‹å‚æ•°ï¼š

```typescript
// tts-v3-bidirection.service.ts
const TTS_CONFIG = {
  // åŸºç¡€é…ç½®
  app: {
    appkey: process.env.VOLCENGINE_APP_KEY,
    token: process.env.VOLCENGINE_ACCESS_KEY,
    cluster: process.env.TTS_CLUSTER || 'default'
  },

  // æ¨¡å‹èµ„æºé…ç½®
  user: {
    uid: 'unique_user_id', // ç”¨æˆ·å”¯ä¸€æ ‡è¯†
    host_uid: 'host_user_id' // ä¸»æ’­ç”¨æˆ·IDï¼ˆå¯é€‰ï¼‰
  },

  // éŸ³é¢‘é…ç½®
  audio: {
    voice_type: 'BV001_streaming', // è¯­éŸ³ç±»å‹
    encoder: 'mp3',               // éŸ³é¢‘ç¼–ç æ ¼å¼
    speed_ratio: 1.0,             // è¯­é€Ÿæ¯”ä¾‹ (0.2-3.0)
    volume_ratio: 1.0,            // éŸ³é‡æ¯”ä¾‹ (0.1-3.0)
    pitch_ratio: 1.0              // éŸ³è°ƒæ¯”ä¾‹ (0.5-2.0)
  },

  // é«˜çº§é…ç½®
  request: {
    reqid: Math.random().toString(36).substring(7), // è¯·æ±‚ID
    frontend_type: 'unitTson',                      // å‰ç«¯ç±»å‹
    nlp: 0,                                         // NLPä¼˜åŒ–
    version: 'v1',                                  // APIç‰ˆæœ¬
    subtitle: 0,                                    // å­—å¹•ç”Ÿæˆ
    break: 0,                                       // è¯­ä¹‰æ–­å¥
    streaming_type: 'duplex',                       // æµå¼ç±»å‹ï¼šduplexï¼ˆåŒå‘ï¼‰
    audio_output_type: 1,                           // éŸ³é¢‘è¾“å‡ºç±»å‹
    platform: 'linux',                              // å¹³å°ç±»å‹
    with_frontend: 1,                               // å‰ç«¯å¤„ç†
    with_backend: 1,                                // åç«¯å¤„ç†
    enable_subtitle: false,                          // å¯ç”¨å­—å¹•
    enable_punctuation: true,                        // å¯ç”¨æ ‡ç‚¹
    sample_rate: 16000                              // é‡‡æ ·ç‡
  }
}
```

### 3. æ”¯æŒçš„è¯­éŸ³ç±»å‹

```typescript
const VOICE_TYPES = {
  // æ•™è‚²ç±»è¯­éŸ³
  educational: [
    { id: 'BV001_streaming', name: 'æ•™å­¦å¥³å£°', desc: 'é€‚åˆæ•™è‚²å†…å®¹è®²è§£' },
    { id: 'BV002_streaming', name: 'æ•™å­¦ç”·å£°', desc: 'æƒå¨æ²‰ç¨³é£æ ¼' },
    { id: 'BV003_streaming', name: 'é’æ˜¥å¥³å£°', desc: 'æ´»æ³¼ç”ŸåŠ¨é£æ ¼' }
  ],

  // å„¿ç«¥ç±»è¯­éŸ³
  children: [
    { id: 'BV101_streaming', name: 'ç«¥å£°å¥³', desc: 'å¯çˆ±æ¸©æŸ”' },
    { id: 'BV102_streaming', name: 'ç«¥å£°ç”·', desc: 'æ´»æ³¼é˜³å…‰' },
    { id: 'BV103_streaming', name: 'å¡é€šéŸ³', desc: 'è¶£å‘³å¡é€š' }
  ],

  // ä¸“ä¸šç±»è¯­éŸ³
  professional: [
    { id: 'BV201_streaming', name: 'ä¸“ä¸šå¥³å£°', desc: 'æ ‡å‡†æ’­éŸ³' },
    { id: 'BV202_streaming', name: 'ä¸“ä¸šç”·å£°', desc: 'æ–°é—»æ’­æŠ¥' },
    { id: 'BV203_streaming', name: 'å•†åŠ¡å¥³å£°', desc: 'å•†åŠ¡æ¼”è®²' }
  ],

  // æƒ…æ„Ÿç±»è¯­éŸ³
  emotional: [
    { id: 'BV301_streaming', name: 'æ¸©æŸ”å¥³å£°', desc: 'äº²åˆ‡è‡ªç„¶' },
    { id: 'BV302_streaming', name: 'ç£æ€§ç”·å£°', desc: 'æ·±æƒ…å¯Œæœ‰æ„ŸæŸ“åŠ›' },
    { id: 'BV303_streaming', name: 'æ´»åŠ›å¥³å£°', desc: 'çƒ­æƒ…æ´‹æº¢' }
  ]
}
```

## ğŸŒ åŒå‘è¯­éŸ³æµå®ç°

### 1. å‰ç«¯WebSocketè¿æ¥

```typescript
// TextToSpeech.vue ä¸­çš„WebSocketè¿æ¥
class TTSWebSocketClient {
  private ws: WebSocket | null = null
  private reconnectAttempts = 0
  private maxReconnectAttempts = 3

  async connectWebSocket(config: TTSConfig) {
    try {
      // å»ºç«‹WebSocketè¿æ¥
      this.ws = new WebSocket(`ws://localhost:3000/api/tts/websocket`)

      // è¿æ¥æ‰“å¼€äº‹ä»¶
      this.ws.onopen = () => {
        console.log('ğŸ”— TTS WebSocketè¿æ¥å·²å»ºç«‹')
        this.sendConnectionStart(config)
      }

      // æ¥æ”¶æ¶ˆæ¯äº‹ä»¶
      this.ws.onmessage = (event) => {
        const data = JSON.parse(event.data)
        this.handleTTSResponse(data)
      }

      // è¿æ¥å…³é—­äº‹ä»¶
      this.ws.onclose = () => {
        console.log('ğŸ”Œ TTS WebSocketè¿æ¥å·²å…³é—­')
        this.handleReconnect()
      }

      // è¿æ¥é”™è¯¯äº‹ä»¶
      this.ws.onerror = (error) => {
        console.error('âŒ TTS WebSocketè¿æ¥é”™è¯¯:', error)
        this.handleConnectionError(error)
      }

    } catch (error) {
      console.error('âŒ å»ºç«‹TTS WebSocketè¿æ¥å¤±è´¥:', error)
      throw error
    }
  }

  // å‘é€è¿æ¥å¼€å§‹æŒ‡ä»¤
  private sendConnectionStart(config: TTSConfig) {
    const message = {
      type: 'START_CONNECTION',
      payload: {
        app_key: config.appKey,
        access_key: config.accessKey,
        resource_id: config.resourceId,
        cluster: config.cluster || 'default'
      }
    }
    this.ws?.send(JSON.stringify(message))
  }

  // å‘é€ä¼šè¯å¼€å§‹æŒ‡ä»¤
  private sendSessionStart(voiceConfig: VoiceConfig) {
    const message = {
      type: 'START_SESSION',
      payload: {
        user: {
          uid: this.generateUserId(),
          host_uid: voiceConfig.hostUid
        },
        audio: {
          voice_type: voiceConfig.voiceType,
          encoder: voiceConfig.encoder,
          speed_ratio: voiceConfig.speedRatio,
          volume_ratio: voiceConfig.volumeRatio,
          pitch_ratio: voiceConfig.pitchRatio
        }
      }
    }
    this.ws?.send(JSON.stringify(message))
  }

  // å‘é€æ–‡æœ¬åˆæˆè¯·æ±‚
  sendTextToSynthesize(text: string, sentenceId: string) {
    const message = {
      type: 'TASK_REQUEST',
      payload: {
        text: text,
        reqid: this.generateRequestId(),
        sentence_id: sentenceId,
        frontend_type: 'unitTson',
        streaming_type: 'duplex'
      }
    }
    this.ws?.send(JSON.stringify(message))
  }

  // å¤„ç†TTSå“åº”
  private handleTTSResponse(data: any) {
    switch (data.type) {
      case 'TTS_RESPONSE':
        if (data.status === 1) {
          // éŸ³é¢‘æ•°æ®æµ
          this.handleAudioStream(data.audio_data, data.sentence_id)
        } else if (data.status === 2) {
          // å¥å­å®Œæˆ
          this.handleSentenceComplete(data.sentence_id)
        } else if (data.status === 3) {
          // å…¨éƒ¨å®Œæˆ
          this.handleSynthesisComplete()
        }
        break

      case 'CONNECTION_ERROR':
        this.handleConnectionError(data.error)
        break

      default:
        console.warn('âš ï¸ æœªçŸ¥çš„TTSå“åº”ç±»å‹:', data.type)
    }
  }

  // å¤„ç†éŸ³é¢‘æµæ•°æ®
  private handleAudioStream(audioData: string, sentenceId: string) {
    // å°†Base64éŸ³é¢‘æ•°æ®è½¬æ¢ä¸ºäºŒè¿›åˆ¶
    const binaryAudio = this.base64ToBinary(audioData)

    // åˆ›å»ºéŸ³é¢‘ç‰‡æ®µ
    const audioChunk = new AudioBlob(binaryAudio, {
      type: 'audio/mpeg'
    })

    // è§¦å‘éŸ³é¢‘æ’­æ”¾äº‹ä»¶
    this.emit('audioChunk', {
      chunk: audioChunk,
      sentenceId: sentenceId,
      timestamp: Date.now()
    })

    // ç´¯ç§¯éŸ³é¢‘æ•°æ®ç”¨äºå®Œæ•´éŸ³é¢‘
    this.accumulateAudioData(binaryAudio)
  }
}
```

### 2. åç«¯WebSocketæœåŠ¡å™¨

```typescript
// tts-websocket.gateway.ts
@WebSocketGateway({
  cors: {
    origin: '*',
    credentials: true
  }
})
export class TTSWebSocketGateway implements OnGatewayConnection, OnGatewayDisconnect {

  @WebSocketServer()
  server: Server

  private logger = new Logger(TTSWebSocketGateway.name)
  private clients = new Map<string, Socket>()
  private ttsService = new TtsV3BidirectionService()

  // å®¢æˆ·ç«¯è¿æ¥å¤„ç†
  async handleConnection(client: Socket) {
    this.logger.log(`ğŸ”— å®¢æˆ·ç«¯è¿æ¥: ${client.id}`)
    this.clients.set(client.id, client)

    // è®¾ç½®æ¶ˆæ¯ç›‘å¬å™¨
    client.on('START_CONNECTION', (data) => {
      this.handleStartConnection(client, data)
    })

    client.on('START_SESSION', (data) => {
      this.handleStartSession(client, data)
    })

    client.on('TASK_REQUEST', (data) => {
      this.handleTaskRequest(client, data)
    })

    client.on('disconnect', () => {
      this.handleDisconnect(client)
    })
  }

  // å¤„ç†è¿æ¥å¼€å§‹
  private async handleStartConnection(client: Socket, data: any) {
    try {
      const connectionConfig = {
        appkey: data.app_key,
        token: data.access_key,
        cluster: data.cluster,
        resource_id: data.resource_id
      }

      // åˆ›å»ºTTSè¿æ¥
      await this.ttsService.createConnection(connectionConfig,
        (responseData) => {
          // å‘å®¢æˆ·ç«¯è½¬å‘å“åº”
          client.emit('TTS_RESPONSE', responseData)
        },
        (error) => {
          client.emit('CONNECTION_ERROR', { error: error.message })
        }
      )

      client.emit('CONNECTION_ESTABLISHED', { status: 'connected' })

    } catch (error) {
      this.logger.error('âŒ è¿æ¥å»ºç«‹å¤±è´¥:', error)
      client.emit('CONNECTION_ERROR', { error: error.message })
    }
  }

  // å¤„ç†ä¼šè¯å¼€å§‹
  private async handleStartSession(client: Socket, data: any) {
    try {
      const sessionConfig = {
        user: data.user,
        audio: data.audio
      }

      await this.ttsService.startSession(sessionConfig)
      client.emit('SESSION_STARTED', { status: 'session_active' })

    } catch (error) {
      this.logger.error('âŒ ä¼šè¯å¼€å§‹å¤±è´¥:', error)
      client.emit('SESSION_ERROR', { error: error.message })
    }
  }

  // å¤„ç†æ–‡æœ¬åˆæˆè¯·æ±‚
  private async handleTaskRequest(client: Socket, data: any) {
    try {
      const synthesisRequest = {
        text: data.text,
        reqid: data.reqid,
        sentence_id: data.sentence_id,
        frontend_type: data.frontend_type || 'unitTson',
        streaming_type: data.streaming_type || 'duplex'
      }

      // å‘é€åˆæˆè¯·æ±‚åˆ°è±†åŒ…TTS
      await this.ttsService.sendSynthesisRequest(synthesisRequest)

    } catch (error) {
      this.logger.error('âŒ æ–‡æœ¬åˆæˆè¯·æ±‚å¤±è´¥:', error)
      client.emit('SYNTHESIS_ERROR', {
        error: error.message,
        sentence_id: data.sentence_id
      })
    }
  }

  // å®¢æˆ·ç«¯æ–­å¼€å¤„ç†
  handleDisconnect(client: Socket) {
    this.logger.log(`ğŸ”Œ å®¢æˆ·ç«¯æ–­å¼€: ${client.id}`)
    this.clients.delete(client.id)

    // æ¸…ç†TTSè¿æ¥
    this.ttsService.closeConnection()
  }
}
```

### 3. TTS V3åŒå‘æµæœåŠ¡

```typescript
// tts-v3-bidirection.service.ts
@Injectable()
export class TtsV3BidirectionService {
  private logger = new Logger(TtsV3BidirectionService.name)
  private ws: WebSocket | null = null
  private responseCallback: ((data: any) => void) | null = null
  private errorCallback: ((error: Error) => void) | null = null
  private connectionState: 'disconnected' | 'connecting' | 'connected' = 'disconnected'

  // åˆ›å»ºè¿æ¥
  async createConnection(config: any, onResponse: (data: any) => void, onError: (error: Error) => void) {
    try {
      this.connectionState = 'connecting'
      this.responseCallback = onResponse
      this.errorCallback = onError

      // æ„å»ºè¿æ¥URL
      const wsUrl = `wss://openspeech.bytedance.com/api/v1/tts/ws`

      // åˆ›å»ºWebSocketè¿æ¥
      this.ws = new WebSocket(wsUrl)

      // è¿æ¥äº‹ä»¶å¤„ç†
      this.ws.onopen = () => {
        this.logger.log('ğŸ”— è±†åŒ…TTS WebSocketè¿æ¥å·²å»ºç«‹')
        this.connectionState = 'connected'
        this.sendConnectionPayload(config)
      }

      this.ws.onmessage = (event) => {
        this.handleTTSResponse(event.data)
      }

      this.ws.onclose = () => {
        this.logger.log('ğŸ”Œ è±†åŒ…TTS WebSocketè¿æ¥å·²å…³é—­')
        this.connectionState = 'disconnected'
      }

      this.ws.onerror = (error) => {
        this.logger.error('âŒ è±†åŒ…TTS WebSocketè¿æ¥é”™è¯¯:', error)
        this.connectionState = 'disconnected'
        onError(new Error('WebSocketè¿æ¥å¤±è´¥'))
      }

    } catch (error) {
      this.logger.error('âŒ åˆ›å»ºè±†åŒ…TTSè¿æ¥å¤±è´¥:', error)
      onError(error as Error)
    }
  }

  // å‘é€è¿æ¥è½½è·
  private sendConnectionPayload(config: any) {
    const payload = {
      app: {
        appkey: config.appkey,
        token: config.token,
        cluster: config.cluster
      },
      user: {
        uid: this.generateUid()
      },
      audio: {
        voice_type: 'BV001_streaming',
        encoder: 'mp3',
        speed_ratio: 1.0,
        volume_ratio: 1.0,
        pitch_ratio: 1.0
      },
      request: {
        reqid: this.generateReqid(),
        frontend_type: 'unitTson',
        nlp: 0,
        version: 'v1',
        subtitle: 0,
        break: 0,
        streaming_type: 'duplex',
        audio_output_type: 1,
        platform: 'linux',
        with_frontend: 1,
        with_backend: 1
      }
    }

    const message = {
      type: 'START_CONNECTION',
      payload: payload
    }

    this.ws?.send(JSON.stringify(message))
  }

  // å¼€å§‹ä¼šè¯
  async startSession(config: any) {
    const sessionPayload = {
      user: config.user,
      audio: config.audio
    }

    const message = {
      type: 'START_SESSION',
      payload: sessionPayload
    }

    this.ws?.send(JSON.stringify(message))
  }

  // å‘é€åˆæˆè¯·æ±‚
  async sendSynthesisRequest(request: any) {
    const synthesisPayload = {
      text: request.text,
      reqid: request.reqid,
      sentence_id: request.sentence_id,
      frontend_type: request.frontend_type,
      streaming_type: request.streaming_type,
      version: 'v1'
    }

    const message = {
      type: 'TASK_REQUEST',
      payload: synthesisPayload
    }

    this.ws?.send(JSON.stringify(message))
  }

  // å¤„ç†TTSå“åº”
  private handleTTSResponse(data: string) {
    try {
      const response = JSON.parse(data)

      switch (response.type) {
        case 'CONNECTION_ACK':
          this.logger.log('âœ… è¿æ¥ç¡®è®¤')
          this.responseCallback?.({ type: 'CONNECTION_ESTABLISHED' })
          break

        case 'SESSION_ACK':
          this.logger.log('âœ… ä¼šè¯ç¡®è®¤')
          this.responseCallback?.({ type: 'SESSION_STARTED' })
          break

        case 'TTS_RESPONSE':
          this.handleTTSStream(response)
          break

        case 'FINISH_TTS':
          this.logger.log('âœ… TTSåˆæˆå®Œæˆ')
          this.responseCallback?.({
            type: 'TTS_RESPONSE',
            status: 3,
            message: 'åˆæˆå®Œæˆ'
          })
          break

        case 'ERROR':
          this.logger.error('âŒ TTSé”™è¯¯:', response.payload)
          this.errorCallback?.(new Error(response.payload.message))
          break

        default:
          this.logger.warn('âš ï¸ æœªçŸ¥å“åº”ç±»å‹:', response.type)
      }

    } catch (error) {
      this.logger.error('âŒ è§£æTTSå“åº”å¤±è´¥:', error)
      this.errorCallback?.(error as Error)
    }
  }

  // å¤„ç†TTSæµæ•°æ®
  private handleTTSStream(response: any) {
    if (response.status === 1) {
      // éŸ³é¢‘æ•°æ®æµ
      this.responseCallback?.({
        type: 'TTS_RESPONSE',
        status: 1,
        audio_data: response.payload.audio_data,
        sentence_id: response.payload.sentence_id,
        seq: response.payload.seq
      })

    } else if (response.status === 2) {
      // å¥å­å®Œæˆ
      this.responseCallback?.({
        type: 'TTS_RESPONSE',
        status: 2,
        sentence_id: response.payload.sentence_id,
        duration: response.payload.duration_ms
      })
    }
  }

  // å…³é—­è¿æ¥
  closeConnection() {
    if (this.ws) {
      this.ws.close()
      this.ws = null
    }
    this.connectionState = 'disconnected'
    this.responseCallback = null
    this.errorCallback = null
  }

  // å·¥å…·æ–¹æ³•
  private generateUid(): string {
    return `user_${Date.now()}_${Math.random().toString(36).substring(7)}`
  }

  private generateReqid(): string {
    return `req_${Date.now()}_${Math.random().toString(36).substring(7)}`
  }
}
```

## ğŸ”„ WebSocketåè®®è¯¦è§£

### åè®®æ¶ˆæ¯æ ¼å¼

```typescript
interface TTSMessage {
  type: 'START_CONNECTION' | 'START_SESSION' | 'TASK_REQUEST' | 'TTS_RESPONSE' | 'FINISH_TTS' | 'ERROR'
  payload: any
  timestamp?: number
  id?: string
}
```

### 1. è¿æ¥å»ºç«‹é˜¶æ®µ

```typescript
// å®¢æˆ·ç«¯å‘é€
{
  type: "START_CONNECTION",
  payload: {
    app: {
      appkey: "your_app_key",
      token: "your_access_token",
      cluster: "default"
    },
    user: {
      uid: "user_unique_id"
    },
    audio: {
      voice_type: "BV001_streaming",
      encoder: "mp3",
      speed_ratio: 1.0,
      volume_ratio: 1.0,
      pitch_ratio: 1.0
    },
    request: {
      reqid: "unique_request_id",
      frontend_type: "unitTson",
      streaming_type: "duplex",
      version: "v1"
    }
  }
}

// æœåŠ¡ç«¯å“åº”
{
  type: "CONNECTION_ACK",
  payload: {
    status: "success",
    connection_id: "conn_unique_id"
  }
}
```

### 2. ä¼šè¯å»ºç«‹é˜¶æ®µ

```typescript
// å®¢æˆ·ç«¯å‘é€
{
  type: "START_SESSION",
  payload: {
    user: {
      uid: "user_unique_id",
      host_uid: "host_user_id" // å¯é€‰
    },
    audio: {
      voice_type: "BV001_streaming",
      encoder: "mp3",
      speed_ratio: 1.2,
      volume_ratio: 1.1,
      pitch_ratio: 1.0
    }
  }
}

// æœåŠ¡ç«¯å“åº”
{
  type: "SESSION_ACK",
  payload: {
    status: "success",
    session_id: "session_unique_id"
  }
}
```

### 3. æ–‡æœ¬åˆæˆè¯·æ±‚

```typescript
// å®¢æˆ·ç«¯å‘é€
{
  type: "TASK_REQUEST",
  payload: {
    text: "è¿™æ˜¯è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
    reqid: "request_unique_id",
    sentence_id: "sentence_001",
    frontend_type: "unitTson",
    streaming_type: "duplex"
  }
}
```

### 4. éŸ³é¢‘æµå“åº”

```typescript
// éŸ³é¢‘æ•°æ®æµ (status: 1)
{
  type: "TTS_RESPONSE",
  payload: {
    status: 1,
    audio_data: "base64_encoded_audio_chunk",
    sentence_id: "sentence_001",
    seq: 1,
    timestamp: 1699123456789
  }
}

// å¥å­å®Œæˆ (status: 2)
{
  type: "TTS_RESPONSE",
  payload: {
    status: 2,
    sentence_id: "sentence_001",
    duration_ms: 2500,
    text: "è¿™æ˜¯è¦åˆæˆçš„æ–‡æœ¬å†…å®¹"
  }
}

// å…¨éƒ¨å®Œæˆ (status: 3)
{
  type: "FINISH_TTS",
  payload: {
    total_duration_ms: 5000,
    total_sentences: 2,
    final_status: "success"
  }
}
```

## ğŸ›ï¸ å‰ç«¯ç•Œé¢ç»„ä»¶

### 1. ä¸»è¦åŠŸèƒ½ç‰¹æ€§

```vue
<!-- TextToSpeech.vue æ ¸å¿ƒåŠŸèƒ½ -->
<template>
  <div class="tts-container">
    <!-- è¯­éŸ³ç±»å‹é€‰æ‹© -->
    <el-card title="è¯­éŸ³ç±»å‹">
      <el-radio-group v-model="ttsConfig.voiceType">
        <el-radio
          v-for="voice in availableVoices"
          :key="voice.id"
          :label="voice.id"
        >
          <div class="voice-option">
            <div class="voice-name">{{ voice.name }}</div>
            <div class="voice-desc">{{ voice.description }}</div>
          </div>
        </el-radio>
      </el-radio-group>
    </el-card>

    <!-- å‚æ•°è°ƒèŠ‚ -->
    <el-card title="å‚æ•°è°ƒèŠ‚">
      <el-form :model="ttsConfig">
        <el-form-item label="è¯­é€Ÿ">
          <el-slider
            v-model="ttsConfig.speedRatio"
            :min="0.2"
            :max="3.0"
            :step="0.1"
            :format-tooltip="formatSpeed"
          />
        </el-form-item>

        <el-form-item label="éŸ³é‡">
          <el-slider
            v-model="ttsConfig.volumeRatio"
            :min="0.1"
            :max="3.0"
            :step="0.1"
            :format-tooltip="formatVolume"
          />
        </el-form-item>

        <el-form-item label="éŸ³è°ƒ">
          <el-slider
            v-model="ttsConfig.pitchRatio"
            :min="0.5"
            :max="2.0"
            :step="0.1"
            :format-tooltip="formatPitch"
          />
        </el-form-item>
      </el-form>
    </el-card>

    <!-- æ–‡æœ¬è¾“å…¥ -->
    <el-card title="æ–‡æœ¬å†…å®¹">
      <el-input
        v-model="inputText"
        type="textarea"
        :rows="4"
        placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹..."
        maxlength="5000"
        show-word-limit
      />
    </el-card>

    <!-- æ§åˆ¶æŒ‰é’® -->
    <div class="control-buttons">
      <el-button
        type="primary"
        :loading="isGenerating"
        @click="startSynthesis"
      >
        <i class="el-icon-microphone"></i>
        å¼€å§‹åˆæˆ
      </el-button>

      <el-button
        v-if="isPlaying"
        type="danger"
        @click="stopPlayback"
      >
        <i class="el-icon-video-pause"></i>
        åœæ­¢æ’­æ”¾
      </el-button>

      <el-button
        v-if="hasAudioData"
        type="success"
        @click="downloadAudio"
      >
        <i class="el-icon-download"></i>
        ä¸‹è½½éŸ³é¢‘
      </el-button>
    </div>

    <!-- å®æ—¶æ’­æ”¾å™¨ -->
    <div v-if="currentAudioUrl" class="audio-player">
      <audio
        ref="audioPlayer"
        :src="currentAudioUrl"
        controls
        @ended="handleAudioEnded"
        @timeupdate="handleTimeUpdate"
      />
      <div class="progress-bar">
        <el-progress
          :percentage="playProgress"
          :show-text="false"
        />
      </div>
    </div>

    <!-- è¿æ¥çŠ¶æ€æŒ‡ç¤º -->
    <div class="connection-status">
      <el-tag
        :type="connectionStatusType"
        effect="dark"
      >
        {{ connectionStatusText }}
      </el-tag>
    </div>
  </div>
</template>
```

### 2. æ ¸å¿ƒé€»è¾‘å®ç°

```typescript
import { ref, reactive, computed, onMounted, onUnmounted } from 'vue'
import { ElMessage } from 'element-plus'

export default {
  setup() {
    // å“åº”å¼æ•°æ®
    const inputText = ref('')
    const isGenerating = ref(false)
    const isPlaying = ref(false)
    const currentAudioUrl = ref('')
    const playProgress = ref(0)
    const hasAudioData = ref(false)
    const connectionStatus = ref<'disconnected' | 'connecting' | 'connected'>('disconnected')

    // TTSé…ç½®
    const ttsConfig = reactive({
      voiceType: 'BV001_streaming',
      encoder: 'mp3',
      speedRatio: 1.0,
      volumeRatio: 1.0,
      pitchRatio: 1.0
    })

    // å¯ç”¨è¯­éŸ³åˆ—è¡¨
    const availableVoices = ref([
      { id: 'BV001_streaming', name: 'æ•™å­¦å¥³å£°', description: 'é€‚åˆæ•™è‚²å†…å®¹è®²è§£' },
      { id: 'BV002_streaming', name: 'æ•™å­¦ç”·å£°', description: 'æƒå¨æ²‰ç¨³é£æ ¼' },
      { id: 'BV101_streaming', name: 'ç«¥å£°å¥³', description: 'å¯çˆ±æ¸©æŸ”' },
      { id: 'BV301_streaming', name: 'æ¸©æŸ”å¥³å£°', description: 'äº²åˆ‡è‡ªç„¶' }
    ])

    // WebSocketå®¢æˆ·ç«¯
    let ttsClient: TTSWebSocketClient | null = null
    let accumulatedAudioData: ArrayBuffer[] = []

    // è®¡ç®—å±æ€§
    const connectionStatusType = computed(() => {
      switch (connectionStatus.value) {
        case 'connected': return 'success'
        case 'connecting': return 'warning'
        default: return 'danger'
      }
    })

    const connectionStatusText = computed(() => {
      switch (connectionStatus.value) {
        case 'connected': return 'å·²è¿æ¥'
        case 'connecting': return 'è¿æ¥ä¸­...'
        default: return 'æœªè¿æ¥'
      }
    })

    // åˆå§‹åŒ–WebSocketè¿æ¥
    const initializeConnection = async () => {
      try {
        connectionStatus.value = 'connecting'

        ttsClient = new TTSWebSocketClient()

        // è®¾ç½®äº‹ä»¶ç›‘å¬å™¨
        ttsClient.on('connectionEstablished', () => {
          connectionStatus.value = 'connected'
          ElMessage.success('TTSæœåŠ¡è¿æ¥æˆåŠŸ')
        })

        ttsClient.on('audioChunk', (data) => {
          handleAudioChunk(data)
        })

        ttsClient.on('synthesisComplete', () => {
          handleSynthesisComplete()
        })

        ttsClient.on('error', (error) => {
          handleError(error)
        })

        // å»ºç«‹è¿æ¥
        await ttsClient.connect({
          appKey: process.env.VUE_APP_TTS_APP_KEY,
          accessKey: process.env.VUE_APP_TTS_ACCESS_KEY,
          resourceId: process.env.VUE_APP_TTS_RESOURCE_ID
        })

      } catch (error) {
        connectionStatus.value = 'disconnected'
        ElMessage.error(`TTSè¿æ¥å¤±è´¥: ${error.message}`)
      }
    }

    // å¼€å§‹åˆæˆ
    const startSynthesis = async () => {
      if (!inputText.value.trim()) {
        ElMessage.warning('è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹')
        return
      }

      if (connectionStatus.value !== 'connected') {
        ElMessage.warning('TTSæœåŠ¡æœªè¿æ¥ï¼Œæ­£åœ¨é‡è¿...')
        await initializeConnection()
      }

      try {
        isGenerating.value = true
        accumulatedAudioData = []

        // å‘é€ä¼šè¯å¼€å§‹é…ç½®
        await ttsClient?.startSession({
          voiceType: ttsConfig.voiceType,
          speedRatio: ttsConfig.speedRatio,
          volumeRatio: ttsConfig.volumeRatio,
          pitchRatio: ttsConfig.pitchRatio
        })

        // åˆ†å¥å‘é€æ–‡æœ¬
        const sentences = splitTextToSentences(inputText.value)
        for (let i = 0; i < sentences.length; i++) {
          const sentenceId = `sentence_${i + 1}`
          await ttsClient?.sendTextToSynthesize(sentences[i], sentenceId)

          // æ·»åŠ å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
          await new Promise(resolve => setTimeout(resolve, 100))
        }

        ElMessage.success('æ–‡æœ¬åˆæˆè¯·æ±‚å·²å‘é€')

      } catch (error) {
        ElMessage.error(`åˆæˆå¤±è´¥: ${error.message}`)
      } finally {
        isGenerating.value = false
      }
    }

    // å¤„ç†éŸ³é¢‘æ•°æ®å—
    const handleAudioChunk = (data: any) => {
      // ç´¯ç§¯éŸ³é¢‘æ•°æ®
      accumulatedAudioData.push(data.chunk)

      // å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªéŸ³é¢‘å—ï¼Œåˆ›å»ºæ’­æ”¾å™¨
      if (!currentAudioUrl.value) {
        createAudioPlayer()
      }

      hasAudioData.value = true
    }

    // åˆ›å»ºéŸ³é¢‘æ’­æ”¾å™¨
    const createAudioPlayer = () => {
      // å°†ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®åˆå¹¶ä¸ºå®Œæ•´çš„éŸ³é¢‘
      const audioBlob = new Blob(accumulatedAudioData, { type: 'audio/mpeg' })
      currentAudioUrl.value = URL.createObjectURL(audioBlob)

      // è‡ªåŠ¨æ’­æ”¾
      nextTick(() => {
        const audioPlayer = document.querySelector('audio')
        if (audioPlayer) {
          audioPlayer.play()
          isPlaying.value = true
        }
      })
    }

    // åˆæˆå®Œæˆå¤„ç†
    const handleSynthesisComplete = () => {
      isGenerating.value = false
      ElMessage.success('éŸ³é¢‘åˆæˆå®Œæˆ')

      // æ›´æ–°æ’­æ”¾å™¨
      if (accumulatedAudioData.length > 0) {
        createAudioPlayer()
      }
    }

    // ä¸‹è½½éŸ³é¢‘
    const downloadAudio = () => {
      if (!currentAudioUrl.value) return

      const link = document.createElement('a')
      link.href = currentAudioUrl.value
      link.download = `tts_audio_${Date.now()}.mp3`
      document.body.appendChild(link)
      link.click()
      document.body.removeChild(link)

      ElMessage.success('éŸ³é¢‘ä¸‹è½½æˆåŠŸ')
    }

    // é”™è¯¯å¤„ç†
    const handleError = (error: any) => {
      ElMessage.error(`TTSé”™è¯¯: ${error.message}`)
      isGenerating.value = false
      isPlaying.value = false
    }

    // å·¥å…·æ–¹æ³•
    const formatSpeed = (value: number) => `${value}x`
    const formatVolume = (value: number) => `${Math.round(value * 100)}%`
    const formatPitch = (value: number) => `${value}x`

    const splitTextToSentences = (text: string): string[] => {
      // æŒ‰æ ‡ç‚¹ç¬¦å·åˆ†å¥
      return text.split(/[ã€‚ï¼ï¼Ÿ.!?]+/).filter(s => s.trim().length > 0)
    }

    // ç”Ÿå‘½å‘¨æœŸ
    onMounted(() => {
      initializeConnection()
    })

    onUnmounted(() => {
      ttsClient?.disconnect()
    })

    return {
      inputText,
      isGenerating,
      isPlaying,
      currentAudioUrl,
      playProgress,
      hasAudioData,
      connectionStatus,
      connectionStatusType,
      connectionStatusText,
      ttsConfig,
      availableVoices,
      startSynthesis,
      downloadAudio,
      formatSpeed,
      formatVolume,
      formatPitch
    }
  }
}
```

## ğŸ”Š éŸ³é¢‘å¤„ç†å’Œæ’­æ”¾

### 1. éŸ³é¢‘æµå¤„ç†

```typescript
class AudioStreamProcessor {
  private audioContext: AudioContext
  private accumulatedChunks: Uint8Array[] = []
  private totalDuration: number = 0

  constructor() {
    this.audioContext = new AudioContext()
  }

  // å¤„ç†éŸ³é¢‘æ•°æ®å—
  processAudioChunk(base64Data: string): Promise<ArrayBuffer> {
    return new Promise((resolve) => {
      // è§£ç Base64æ•°æ®
      const binaryString = atob(base64Data)
      const bytes = new Uint8Array(binaryString.length)

      for (let i = 0; i < binaryString.length; i++) {
        bytes[i] = binaryString.charCodeAt(i)
      }

      // ç´¯ç§¯æ•°æ®
      this.accumulatedChunks.push(bytes)

      // è§£ç éŸ³é¢‘
      this.audioContext.decodeAudioData(bytes.buffer,
        (audioBuffer) => {
          this.totalDuration += audioBuffer.duration
          resolve(audioBuffer)
        },
        (error) => {
          console.error('éŸ³é¢‘è§£ç å¤±è´¥:', error)
        }
      )
    })
  }

  // ç”Ÿæˆå®Œæ•´éŸ³é¢‘æ–‡ä»¶
  generateCompleteAudio(): Blob {
    // åˆå¹¶æ‰€æœ‰éŸ³é¢‘å—
    const totalLength = this.accumulatedChunks.reduce(
      (sum, chunk) => sum + chunk.length, 0
    )

    const combinedArray = new Uint8Array(totalLength)
    let offset = 0

    for (const chunk of this.accumulatedChunks) {
      combinedArray.set(chunk, offset)
      offset += chunk.length
    }

    return new Blob([combinedArray], { type: 'audio/mpeg' })
  }

  // è·å–éŸ³é¢‘æ€»æ—¶é•¿
  getTotalDuration(): number {
    return this.totalDuration
  }

  // æ¸…ç†èµ„æº
  cleanup() {
    this.accumulatedChunks = []
    this.totalDuration = 0
    this.audioContext.close()
  }
}
```

### 2. å®æ—¶éŸ³é¢‘æ’­æ”¾å™¨

```typescript
class RealtimeAudioPlayer {
  private audioContext: AudioContext
  private sourceNode: AudioBufferSourceNode | null = null
  private gainNode: GainNode
  private audioQueue: AudioBuffer[] = []
  private isPlaying: boolean = false
  private currentBufferIndex: number = 0

  constructor() {
    this.audioContext = new AudioContext()
    this.gainNode = this.audioContext.createGain()
    this.gainNode.connect(this.audioContext.destination)
  }

  // æ·»åŠ éŸ³é¢‘åˆ°é˜Ÿåˆ—
  addAudioBuffer(audioBuffer: AudioBuffer) {
    this.audioQueue.push(audioBuffer)

    // å¦‚æœå½“å‰æ²¡æœ‰æ’­æ”¾ï¼Œè‡ªåŠ¨å¼€å§‹æ’­æ”¾
    if (!this.isPlaying) {
      this.startPlayback()
    }
  }

  // å¼€å§‹æ’­æ”¾
  private startPlayback() {
    if (this.audioQueue.length === 0) return

    this.isPlaying = true
    this.playNextBuffer()
  }

  // æ’­æ”¾ä¸‹ä¸€ä¸ªéŸ³é¢‘ç¼“å†²åŒº
  private playNextBuffer() {
    if (this.currentBufferIndex >= this.audioQueue.length) {
      this.isPlaying = false
      this.currentBufferIndex = 0
      return
    }

    const audioBuffer = this.audioQueue[this.currentBufferIndex]
    this.sourceNode = this.audioContext.createBufferSource()
    this.sourceNode.buffer = audioBuffer

    // è¿æ¥éŸ³é¢‘èŠ‚ç‚¹
    this.sourceNode.connect(this.gainNode)

    // è®¾ç½®æ’­æ”¾ç»“æŸå›è°ƒ
    this.sourceNode.onended = () => {
      this.currentBufferIndex++
      this.playNextBuffer()
    }

    // å¼€å§‹æ’­æ”¾
    this.sourceNode.start(0)
  }

  // è®¾ç½®éŸ³é‡
  setVolume(volume: number) {
    this.gainNode.gain.value = volume
  }

  // åœæ­¢æ’­æ”¾
  stopPlayback() {
    if (this.sourceNode) {
      this.sourceNode.stop()
      this.sourceNode = null
    }

    this.isPlaying = false
    this.currentBufferIndex = 0
  }

  // æ’­æ”¾çŠ¶æ€
  getPlaybackState(): boolean {
    return this.isPlaying
  }

  // æ¸…ç†èµ„æº
  cleanup() {
    this.stopPlayback()
    this.audioQueue = []
    this.audioContext.close()
  }
}
```

## ğŸ“‹ APIæ¥å£æ–‡æ¡£

### 1. HTTP APIæ¥å£

```typescript
// POST /api/tts/synthesis
interface TTSSynthesisRequest {
  text: string                    // è¦åˆæˆçš„æ–‡æœ¬
  voiceType: string              // è¯­éŸ³ç±»å‹
  speedRatio?: number            // è¯­é€Ÿæ¯”ä¾‹ (0.2-3.0)
  volumeRatio?: number           // éŸ³é‡æ¯”ä¾‹ (0.1-3.0)
  pitchRatio?: number            // éŸ³è°ƒæ¯”ä¾‹ (0.5-2.0)
  outputFormat?: 'mp3' | 'wav'   // è¾“å‡ºæ ¼å¼
  sampleRate?: number            // é‡‡æ ·ç‡ (16000|22050|24000|44100)
}

interface TTSSynthesisResponse {
  success: boolean
  data: {
    audioUrl: string             // éŸ³é¢‘æ–‡ä»¶URL
    duration: number             // éŸ³é¢‘æ—¶é•¿(ç§’)
    textLength: number           // æ–‡æœ¬é•¿åº¦
    voiceType: string           // ä½¿ç”¨çš„è¯­éŸ³ç±»å‹
  }
  message?: string
}
```

### 2. WebSocket APIæ¥å£

```typescript
// è¿æ¥é…ç½®æ¥å£
interface ConnectionConfig {
  appKey: string                 // åº”ç”¨Key
  accessKey: string             // è®¿é—®å¯†é’¥
  resourceId: string            // èµ„æºID
  cluster?: string              // é›†ç¾¤åç§°
}

// ä¼šè¯é…ç½®æ¥å£
interface SessionConfig {
  user: {
    uid: string                  // ç”¨æˆ·ID
    hostUid?: string            // ä¸»æ’­ç”¨æˆ·ID
  }
  audio: {
    voiceType: string           // è¯­éŸ³ç±»å‹
    encoder: string             // ç¼–ç æ ¼å¼
    speedRatio: number          // è¯­é€Ÿæ¯”ä¾‹
    volumeRatio: number         // éŸ³é‡æ¯”ä¾‹
    pitchRatio: number          // éŸ³è°ƒæ¯”ä¾‹
  }
}

// åˆæˆè¯·æ±‚æ¥å£
interface SynthesisRequest {
  text: string                  // è¦åˆæˆçš„æ–‡æœ¬
  reqid: string                // è¯·æ±‚ID
  sentenceId: string           // å¥å­ID
  frontendType?: string        // å‰ç«¯ç±»å‹
  streamingType?: string       // æµå¼ç±»å‹
}
```

## ğŸš€ éƒ¨ç½²å’Œé…ç½®

### 1. ç¯å¢ƒè¦æ±‚

```bash
# Node.jsç‰ˆæœ¬
node >= 16.0.0
npm >= 8.0.0

# ç³»ç»Ÿä¾èµ–
ffmpeg (ç”¨äºéŸ³é¢‘å¤„ç†)
openssl (ç”¨äºSSLè¯ä¹¦)
```

### 2. å®‰è£…æ­¥éª¤

```bash
# 1. å®‰è£…ä¾èµ–
npm install

# 2. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥è±†åŒ…TTSç›¸å…³é…ç½®

# 3. å¯åŠ¨æœåŠ¡
npm run start:all

# 4. éªŒè¯æœåŠ¡
curl http://localhost:3000/api/health
```

### 3. ç”Ÿäº§ç¯å¢ƒé…ç½®

```typescript
// production.config.ts
export const productionConfig = {
  // è±†åŒ…TTSé…ç½®
  tts: {
    maxConcurrentConnections: 100,    // æœ€å¤§å¹¶å‘è¿æ¥æ•°
    connectionTimeout: 30000,         // è¿æ¥è¶…æ—¶(ms)
    maxTextLength: 5000,              // æœ€å¤§æ–‡æœ¬é•¿åº¦
    supportedFormats: ['mp3', 'wav'], // æ”¯æŒçš„éŸ³é¢‘æ ¼å¼

    // è¯­éŸ³ç¼“å­˜é…ç½®
    cache: {
      enabled: true,
      ttl: 3600,                      // ç¼“å­˜æ—¶é—´(ç§’)
      maxSize: 1000                   // æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
    },

    // é™æµé…ç½®
    rateLimit: {
      windowMs: 60000,                // æ—¶é—´çª—å£(ms)
      maxRequests: 100                // æœ€å¤§è¯·æ±‚æ•°
    }
  },

  // WebSocketé…ç½®
  websocket: {
    heartbeatInterval: 30000,          // å¿ƒè·³é—´éš”(ms)
    maxReconnectAttempts: 5,          // æœ€å¤§é‡è¿æ¬¡æ•°
    reconnectDelay: 5000              // é‡è¿å»¶è¿Ÿ(ms)
  }
}
```

## ğŸ” ç›‘æ§å’Œè°ƒè¯•

### 1. æ—¥å¿—è®°å½•

```typescript
// tts-logger.service.ts
@Injectable()
export class TTSLoggerService {
  private logger = new Logger(TTSLoggerService.name)

  // è®°å½•è¿æ¥äº‹ä»¶
  logConnectionEvent(userId: string, event: string, metadata?: any) {
    this.logger.log(`ğŸ”— ç”¨æˆ·${userId} TTSè¿æ¥äº‹ä»¶: ${event}`, metadata)
  }

  // è®°å½•åˆæˆäº‹ä»¶
  logSynthesisEvent(userId: string, textLength: number, duration: number) {
    this.logger.log(`ğŸµ ç”¨æˆ·${userId} TTSåˆæˆ: ${textLength}å­—ç¬¦, ${duration}ç§’`)
  }

  // è®°å½•é”™è¯¯äº‹ä»¶
  logError(userId: string, error: Error, context?: any) {
    this.logger.error(`âŒ ç”¨æˆ·${userId} TTSé”™è¯¯: ${error.message}`, {
      stack: error.stack,
      context
    })
  }

  // è®°å½•æ€§èƒ½æŒ‡æ ‡
  logPerformanceMetrics(userId: string, metrics: {
    connectionTime: number
    synthesisTime: number
    totalDuration: number
    audioSize: number
  }) {
    this.logger.log(`ğŸ“Š ç”¨æˆ·${userId} æ€§èƒ½æŒ‡æ ‡:`, metrics)
  }
}
```

### 2. æ€§èƒ½ç›‘æ§

```typescript
// tts-metrics.service.ts
@Injectable()
export class TTSMetricsService {
  private metrics = {
    totalConnections: 0,
    activeConnections: 0,
    totalSynthesisRequests: 0,
    successfulSynthesis: 0,
    failedSynthesis: 0,
    averageSynthesisTime: 0,
    totalAudioGenerated: 0
  }

  // è®°å½•è¿æ¥å»ºç«‹
  recordConnection() {
    this.metrics.totalConnections++
    this.metrics.activeConnections++
  }

  // è®°å½•è¿æ¥æ–­å¼€
  recordDisconnection() {
    this.metrics.activeConnections = Math.max(0, this.metrics.activeConnections - 1)
  }

  // è®°å½•åˆæˆè¯·æ±‚
  recordSynthesisRequest(duration: number, audioSize: number) {
    this.metrics.totalSynthesisRequests++
    this.metrics.successfulSynthesis++
    this.metrics.totalAudioGenerated += audioSize

    // æ›´æ–°å¹³å‡åˆæˆæ—¶é—´
    this.metrics.averageSynthesisTime =
      (this.metrics.averageSynthesisTime * (this.metrics.successfulSynthesis - 1) + duration)
      / this.metrics.successfulSynthesis
  }

  // è®°å½•åˆæˆå¤±è´¥
  recordSynthesisFailure() {
    this.metrics.failedSynthesis++
  }

  // è·å–æŒ‡æ ‡æ•°æ®
  getMetrics() {
    return { ...this.metrics }
  }
}
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. å‰ç«¯ä¼˜åŒ–

```typescript
// éŸ³é¢‘é¢„åŠ è½½
class AudioPreloader {
  private audioCache = new Map<string, AudioBuffer>()

  async preloadAudio(voiceType: string, text: string) {
    const cacheKey = `${voiceType}_${text.hashCode()}`

    if (!this.audioCache.has(cacheKey)) {
      // é¢„åŠ è½½éŸ³é¢‘
      const audioBuffer = await this.synthesizeAudio(voiceType, text)
      this.audioCache.set(cacheKey, audioBuffer)
    }

    return this.audioCache.get(cacheKey)
  }
}

// æ‡’åŠ è½½WebSocketè¿æ¥
class LazyWebSocketManager {
  private connectionPromise: Promise<void> | null = null

  async getConnection(): Promise<WebSocket> {
    if (!this.connectionPromise) {
      this.connectionPromise = this.establishConnection()
    }

    return this.connectionPromise
  }

  private async establishConnection(): Promise<WebSocket> {
    // å»¶è¿Ÿå»ºç«‹è¿æ¥
    return new WebSocket('ws://localhost:3000/tts')
  }
}
```

### 2. åç«¯ä¼˜åŒ–

```typescript
// è¿æ¥æ± ç®¡ç†
class TTSConnectionPool {
  private pool: WebSocket[] = []
  private maxConnections: number = 50

  async getConnection(): Promise<WebSocket> {
    if (this.pool.length > 0) {
      return this.pool.pop()!
    }

    if (this.pool.length < this.maxConnections) {
      return this.createConnection()
    }

    throw new Error('è¿æ¥æ± å·²æ»¡')
  }

  releaseConnection(connection: WebSocket) {
    if (connection.readyState === WebSocket.OPEN) {
      this.pool.push(connection)
    } else {
      connection.close()
    }
  }
}

// éŸ³é¢‘æ•°æ®å‹ç¼©
class AudioCompressor {
  compressAudioData(audioData: ArrayBuffer): Promise<ArrayBuffer> {
    // ä½¿ç”¨Web Audio APIè¿›è¡ŒéŸ³é¢‘å‹ç¼©
    return new Promise((resolve) => {
      const audioContext = new AudioContext()
      audioContext.decodeAudioData(audioData, (audioBuffer) => {
        // å‹ç¼©é€»è¾‘
        const compressedBuffer = this.compressBuffer(audioBuffer)
        resolve(compressedBuffer)
      })
    })
  }

  private compressBuffer(buffer: AudioBuffer): ArrayBuffer {
    // å®ç°éŸ³é¢‘å‹ç¼©ç®—æ³•
    // é™ä½é‡‡æ ·ç‡ã€å‡å°‘å£°é“ç­‰
    return buffer
  }
}
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

1. **è¿æ¥å»ºç«‹å¤±è´¥**
   ```typescript
   // æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œè®¤è¯ä¿¡æ¯
   const diagnoseConnection = async () => {
     try {
       // æµ‹è¯•ç½‘ç»œè¿é€šæ€§
       await fetch('https://openspeech.bytedance.com/api/health')

       // éªŒè¯è®¤è¯ä¿¡æ¯
       const authResult = await validateCredentials()

       return {
         networkOk: true,
         authValid: authResult.valid,
         errorMessage: null
       }
     } catch (error) {
       return {
         networkOk: false,
         authValid: false,
         errorMessage: error.message
       }
     }
   }
   ```

2. **éŸ³é¢‘åˆæˆå¤±è´¥**
   ```typescript
   // æ£€æŸ¥æ–‡æœ¬å†…å®¹å’Œå‚æ•°é…ç½®
   const validateSynthesisParams = (text: string, config: TTSConfig) => {
     const errors = []

     if (text.length === 0) {
       errors.push('æ–‡æœ¬å†…å®¹ä¸èƒ½ä¸ºç©º')
     }

     if (text.length > 5000) {
       errors.push('æ–‡æœ¬é•¿åº¦è¶…è¿‡é™åˆ¶')
     }

     if (config.speedRatio < 0.2 || config.speedRatio > 3.0) {
       errors.push('è¯­é€Ÿå‚æ•°è¶…å‡ºèŒƒå›´')
     }

     return errors
   }
   ```

3. **éŸ³é¢‘æ’­æ”¾é—®é¢˜**
   ```typescript
   // æ£€æŸ¥æµè§ˆå™¨éŸ³é¢‘æ”¯æŒ
   const checkAudioSupport = (): boolean => {
     const audio = document.createElement('audio')
     return !!(audio.canPlayType && audio.canPlayType('audio/mpeg'))
   }

   // å¤„ç†è‡ªåŠ¨æ’­æ”¾ç­–ç•¥
   const handleAutoplayPolicy = async (): Promise<boolean> => {
     try {
       const audio = new Audio()
       await audio.play()
       return true
     } catch (error) {
       console.warn('è‡ªåŠ¨æ’­æ”¾è¢«é˜»æ­¢ï¼Œéœ€è¦ç”¨æˆ·äº¤äº’')
       return false
     }
   }
   ```

## ğŸ“š æ€»ç»“

è±†åŒ…è¯­éŸ³æµåŒå‘è¯­éŸ³ç³»ç»Ÿå®ç°äº†ï¼š

1. **å®æ—¶åŒå‘é€šä¿¡**: åŸºäºWebSocketçš„ä½å»¶è¿ŸéŸ³é¢‘æµä¼ è¾“
2. **çµæ´»çš„è¯­éŸ³é…ç½®**: æ”¯æŒå¤šç§è¯­éŸ³ç±»å‹å’Œå‚æ•°è°ƒèŠ‚
3. **é«˜è´¨é‡éŸ³é¢‘åˆæˆ**: é›†æˆè±†åŒ…TTSçš„ä¸“ä¸šè¯­éŸ³åˆæˆèƒ½åŠ›
4. **å®Œå–„çš„é”™è¯¯å¤„ç†**: åŒ…å«è¿æ¥ç®¡ç†ã€é‡è¿æœºåˆ¶å’Œæ•…éšœæ¢å¤
5. **æ€§èƒ½ä¼˜åŒ–**: è¿æ¥æ± ã€éŸ³é¢‘ç¼“å­˜å’Œæ•°æ®å‹ç¼©
6. **ç›‘æ§å’Œè°ƒè¯•**: å®Œæ•´çš„æ—¥å¿—è®°å½•å’Œæ€§èƒ½æŒ‡æ ‡ç›‘æ§

è¯¥ç³»ç»Ÿä¸ºæ–°åª’ä½“ä¸­å¿ƒæä¾›äº†ä¸“ä¸šçº§çš„é…éŸ³åŠŸèƒ½ï¼Œæ”¯æŒå®æ—¶è¯­éŸ³åˆæˆå’Œé«˜è´¨é‡éŸ³é¢‘è¾“å‡ºï¼Œå®Œå…¨æ»¡è¶³è§†é¢‘åˆ¶ä½œä¸­çš„é…éŸ³éœ€æ±‚ã€‚